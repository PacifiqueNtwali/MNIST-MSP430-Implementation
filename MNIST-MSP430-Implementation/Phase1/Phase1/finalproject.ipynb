{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU_LaMlFVRGe",
        "outputId": "b7fe7d11-20e8-4c89-e9d3-579e7812560c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.82)] [Waiting for headers] \r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,619 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,506 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,513 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,224 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
            "Fetched 19.5 MB in 3s (6,735 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "gcc is already the newest version (4:11.2.0-1ubuntu1).\n",
            "gcc set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 53 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y gcc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AndrewCarterUK/mnist-neural-network-plain-c.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm3eYK1aVaHr",
        "outputId": "b5938bf3-7110-43b1-9ca5-f801635c822c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mnist-neural-network-plain-c'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 54 (delta 1), reused 0 (delta 0), pack-reused 50 (from 1)\u001b[K\n",
            "Receiving objects: 100% (54/54), 11.26 MiB | 16.56 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd mnist-neural-network-plain-c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvQUoWI-V_si",
        "outputId": "6f5073d9-40e1-4210-feb1-63c39181f503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mnist-neural-network-plain-c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc mnist.c neural_network.c mnist_file.c -o mnist -lm\n"
      ],
      "metadata": {
        "id": "4M0cq8E8WDnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./mnist\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th3yjbwWWKTH",
        "outputId": "fb2f9ff7-0626-4cc0-c4b7-aecad75ca717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0000\tAverage Loss: 4.36\tAccuracy: 0.152\n",
            "Step 0001\tAverage Loss: 3.42\tAccuracy: 0.188\n",
            "Step 0002\tAverage Loss: 2.97\tAccuracy: 0.298\n",
            "Step 0003\tAverage Loss: 2.53\tAccuracy: 0.319\n",
            "Step 0004\tAverage Loss: 2.19\tAccuracy: 0.412\n",
            "Step 0005\tAverage Loss: 2.08\tAccuracy: 0.437\n",
            "Step 0006\tAverage Loss: 1.73\tAccuracy: 0.468\n",
            "Step 0007\tAverage Loss: 1.51\tAccuracy: 0.447\n",
            "Step 0008\tAverage Loss: 1.57\tAccuracy: 0.496\n",
            "Step 0009\tAverage Loss: 1.45\tAccuracy: 0.516\n",
            "Step 0010\tAverage Loss: 1.78\tAccuracy: 0.559\n",
            "Step 0011\tAverage Loss: 1.68\tAccuracy: 0.559\n",
            "Step 0012\tAverage Loss: 1.21\tAccuracy: 0.548\n",
            "Step 0013\tAverage Loss: 1.89\tAccuracy: 0.564\n",
            "Step 0014\tAverage Loss: 1.43\tAccuracy: 0.625\n",
            "Step 0015\tAverage Loss: 1.11\tAccuracy: 0.656\n",
            "Step 0016\tAverage Loss: 0.90\tAccuracy: 0.655\n",
            "Step 0017\tAverage Loss: 0.62\tAccuracy: 0.681\n",
            "Step 0018\tAverage Loss: 0.87\tAccuracy: 0.677\n",
            "Step 0019\tAverage Loss: 0.95\tAccuracy: 0.696\n",
            "Step 0020\tAverage Loss: 0.90\tAccuracy: 0.703\n",
            "Step 0021\tAverage Loss: 0.68\tAccuracy: 0.716\n",
            "Step 0022\tAverage Loss: 0.82\tAccuracy: 0.708\n",
            "Step 0023\tAverage Loss: 0.75\tAccuracy: 0.713\n",
            "Step 0024\tAverage Loss: 0.87\tAccuracy: 0.676\n",
            "Step 0025\tAverage Loss: 0.79\tAccuracy: 0.740\n",
            "Step 0026\tAverage Loss: 0.81\tAccuracy: 0.747\n",
            "Step 0027\tAverage Loss: 0.86\tAccuracy: 0.729\n",
            "Step 0028\tAverage Loss: 0.62\tAccuracy: 0.755\n",
            "Step 0029\tAverage Loss: 0.59\tAccuracy: 0.756\n",
            "Step 0030\tAverage Loss: 0.94\tAccuracy: 0.740\n",
            "Step 0031\tAverage Loss: 0.63\tAccuracy: 0.775\n",
            "Step 0032\tAverage Loss: 0.72\tAccuracy: 0.779\n",
            "Step 0033\tAverage Loss: 0.66\tAccuracy: 0.764\n",
            "Step 0034\tAverage Loss: 0.71\tAccuracy: 0.761\n",
            "Step 0035\tAverage Loss: 0.83\tAccuracy: 0.779\n",
            "Step 0036\tAverage Loss: 0.64\tAccuracy: 0.785\n",
            "Step 0037\tAverage Loss: 0.79\tAccuracy: 0.775\n",
            "Step 0038\tAverage Loss: 0.58\tAccuracy: 0.794\n",
            "Step 0039\tAverage Loss: 0.57\tAccuracy: 0.796\n",
            "Step 0040\tAverage Loss: 0.67\tAccuracy: 0.775\n",
            "Step 0041\tAverage Loss: 0.74\tAccuracy: 0.804\n",
            "Step 0042\tAverage Loss: 0.60\tAccuracy: 0.790\n",
            "Step 0043\tAverage Loss: 0.59\tAccuracy: 0.798\n",
            "Step 0044\tAverage Loss: 0.59\tAccuracy: 0.805\n",
            "Step 0045\tAverage Loss: 0.45\tAccuracy: 0.806\n",
            "Step 0046\tAverage Loss: 0.74\tAccuracy: 0.787\n",
            "Step 0047\tAverage Loss: 0.74\tAccuracy: 0.799\n",
            "Step 0048\tAverage Loss: 0.48\tAccuracy: 0.785\n",
            "Step 0049\tAverage Loss: 0.69\tAccuracy: 0.815\n",
            "Step 0050\tAverage Loss: 0.56\tAccuracy: 0.814\n",
            "Step 0051\tAverage Loss: 0.90\tAccuracy: 0.815\n",
            "Step 0052\tAverage Loss: 0.40\tAccuracy: 0.815\n",
            "Step 0053\tAverage Loss: 0.70\tAccuracy: 0.819\n",
            "Step 0054\tAverage Loss: 0.36\tAccuracy: 0.819\n",
            "Step 0055\tAverage Loss: 0.55\tAccuracy: 0.796\n",
            "Step 0056\tAverage Loss: 0.60\tAccuracy: 0.820\n",
            "Step 0057\tAverage Loss: 0.60\tAccuracy: 0.812\n",
            "Step 0058\tAverage Loss: 0.53\tAccuracy: 0.817\n",
            "Step 0059\tAverage Loss: 0.46\tAccuracy: 0.825\n",
            "Step 0060\tAverage Loss: 0.34\tAccuracy: 0.826\n",
            "Step 0061\tAverage Loss: 0.55\tAccuracy: 0.824\n",
            "Step 0062\tAverage Loss: 0.53\tAccuracy: 0.821\n",
            "Step 0063\tAverage Loss: 0.40\tAccuracy: 0.821\n",
            "Step 0064\tAverage Loss: 0.54\tAccuracy: 0.828\n",
            "Step 0065\tAverage Loss: 0.33\tAccuracy: 0.831\n",
            "Step 0066\tAverage Loss: 0.53\tAccuracy: 0.830\n",
            "Step 0067\tAverage Loss: 0.46\tAccuracy: 0.823\n",
            "Step 0068\tAverage Loss: 0.67\tAccuracy: 0.833\n",
            "Step 0069\tAverage Loss: 0.59\tAccuracy: 0.818\n",
            "Step 0070\tAverage Loss: 0.62\tAccuracy: 0.836\n",
            "Step 0071\tAverage Loss: 0.53\tAccuracy: 0.837\n",
            "Step 0072\tAverage Loss: 0.77\tAccuracy: 0.834\n",
            "Step 0073\tAverage Loss: 0.63\tAccuracy: 0.837\n",
            "Step 0074\tAverage Loss: 0.47\tAccuracy: 0.835\n",
            "Step 0075\tAverage Loss: 0.45\tAccuracy: 0.837\n",
            "Step 0076\tAverage Loss: 0.65\tAccuracy: 0.834\n",
            "Step 0077\tAverage Loss: 0.53\tAccuracy: 0.829\n",
            "Step 0078\tAverage Loss: 0.74\tAccuracy: 0.838\n",
            "Step 0079\tAverage Loss: 0.65\tAccuracy: 0.837\n",
            "Step 0080\tAverage Loss: 0.54\tAccuracy: 0.841\n",
            "Step 0081\tAverage Loss: 0.57\tAccuracy: 0.831\n",
            "Step 0082\tAverage Loss: 0.82\tAccuracy: 0.837\n",
            "Step 0083\tAverage Loss: 0.49\tAccuracy: 0.845\n",
            "Step 0084\tAverage Loss: 0.72\tAccuracy: 0.836\n",
            "Step 0085\tAverage Loss: 0.36\tAccuracy: 0.838\n",
            "Step 0086\tAverage Loss: 0.67\tAccuracy: 0.830\n",
            "Step 0087\tAverage Loss: 1.00\tAccuracy: 0.840\n",
            "Step 0088\tAverage Loss: 0.73\tAccuracy: 0.822\n",
            "Step 0089\tAverage Loss: 0.44\tAccuracy: 0.839\n",
            "Step 0090\tAverage Loss: 0.36\tAccuracy: 0.841\n",
            "Step 0091\tAverage Loss: 0.42\tAccuracy: 0.845\n",
            "Step 0092\tAverage Loss: 0.58\tAccuracy: 0.845\n",
            "Step 0093\tAverage Loss: 0.59\tAccuracy: 0.834\n",
            "Step 0094\tAverage Loss: 0.59\tAccuracy: 0.842\n",
            "Step 0095\tAverage Loss: 0.62\tAccuracy: 0.837\n",
            "Step 0096\tAverage Loss: 0.44\tAccuracy: 0.844\n",
            "Step 0097\tAverage Loss: 0.45\tAccuracy: 0.847\n",
            "Step 0098\tAverage Loss: 0.30\tAccuracy: 0.845\n",
            "Step 0099\tAverage Loss: 0.26\tAccuracy: 0.845\n",
            "Step 0100\tAverage Loss: 0.43\tAccuracy: 0.850\n",
            "Step 0101\tAverage Loss: 0.34\tAccuracy: 0.850\n",
            "Step 0102\tAverage Loss: 0.69\tAccuracy: 0.808\n",
            "Step 0103\tAverage Loss: 0.29\tAccuracy: 0.830\n",
            "Step 0104\tAverage Loss: 0.38\tAccuracy: 0.846\n",
            "Step 0105\tAverage Loss: 0.28\tAccuracy: 0.852\n",
            "Step 0106\tAverage Loss: 0.39\tAccuracy: 0.847\n",
            "Step 0107\tAverage Loss: 0.61\tAccuracy: 0.852\n",
            "Step 0108\tAverage Loss: 0.44\tAccuracy: 0.857\n",
            "Step 0109\tAverage Loss: 0.37\tAccuracy: 0.858\n",
            "Step 0110\tAverage Loss: 0.34\tAccuracy: 0.856\n",
            "Step 0111\tAverage Loss: 0.34\tAccuracy: 0.859\n",
            "Step 0112\tAverage Loss: 0.57\tAccuracy: 0.854\n",
            "Step 0113\tAverage Loss: 0.32\tAccuracy: 0.854\n",
            "Step 0114\tAverage Loss: 0.35\tAccuracy: 0.857\n",
            "Step 0115\tAverage Loss: 0.69\tAccuracy: 0.855\n",
            "Step 0116\tAverage Loss: 0.52\tAccuracy: 0.852\n",
            "Step 0117\tAverage Loss: 0.63\tAccuracy: 0.846\n",
            "Step 0118\tAverage Loss: 0.45\tAccuracy: 0.840\n",
            "Step 0119\tAverage Loss: 0.41\tAccuracy: 0.840\n",
            "Step 0120\tAverage Loss: 0.51\tAccuracy: 0.846\n",
            "Step 0121\tAverage Loss: 0.38\tAccuracy: 0.832\n",
            "Step 0122\tAverage Loss: 0.57\tAccuracy: 0.852\n",
            "Step 0123\tAverage Loss: 0.54\tAccuracy: 0.854\n",
            "Step 0124\tAverage Loss: 0.53\tAccuracy: 0.854\n",
            "Step 0125\tAverage Loss: 0.77\tAccuracy: 0.847\n",
            "Step 0126\tAverage Loss: 0.85\tAccuracy: 0.848\n",
            "Step 0127\tAverage Loss: 0.47\tAccuracy: 0.860\n",
            "Step 0128\tAverage Loss: 0.31\tAccuracy: 0.861\n",
            "Step 0129\tAverage Loss: 0.66\tAccuracy: 0.861\n",
            "Step 0130\tAverage Loss: 0.82\tAccuracy: 0.855\n",
            "Step 0131\tAverage Loss: 0.63\tAccuracy: 0.857\n",
            "Step 0132\tAverage Loss: 0.41\tAccuracy: 0.851\n",
            "Step 0133\tAverage Loss: 0.51\tAccuracy: 0.862\n",
            "Step 0134\tAverage Loss: 0.30\tAccuracy: 0.862\n",
            "Step 0135\tAverage Loss: 0.29\tAccuracy: 0.861\n",
            "Step 0136\tAverage Loss: 0.55\tAccuracy: 0.860\n",
            "Step 0137\tAverage Loss: 0.56\tAccuracy: 0.864\n",
            "Step 0138\tAverage Loss: 0.43\tAccuracy: 0.862\n",
            "Step 0139\tAverage Loss: 0.77\tAccuracy: 0.864\n",
            "Step 0140\tAverage Loss: 0.57\tAccuracy: 0.868\n",
            "Step 0141\tAverage Loss: 0.53\tAccuracy: 0.858\n",
            "Step 0142\tAverage Loss: 0.60\tAccuracy: 0.866\n",
            "Step 0143\tAverage Loss: 0.65\tAccuracy: 0.863\n",
            "Step 0144\tAverage Loss: 0.41\tAccuracy: 0.870\n",
            "Step 0145\tAverage Loss: 0.59\tAccuracy: 0.864\n",
            "Step 0146\tAverage Loss: 0.76\tAccuracy: 0.857\n",
            "Step 0147\tAverage Loss: 0.81\tAccuracy: 0.855\n",
            "Step 0148\tAverage Loss: 0.64\tAccuracy: 0.866\n",
            "Step 0149\tAverage Loss: 0.39\tAccuracy: 0.870\n",
            "Step 0150\tAverage Loss: 0.29\tAccuracy: 0.873\n",
            "Step 0151\tAverage Loss: 0.50\tAccuracy: 0.871\n",
            "Step 0152\tAverage Loss: 0.40\tAccuracy: 0.872\n",
            "Step 0153\tAverage Loss: 0.34\tAccuracy: 0.869\n",
            "Step 0154\tAverage Loss: 0.40\tAccuracy: 0.871\n",
            "Step 0155\tAverage Loss: 0.47\tAccuracy: 0.873\n",
            "Step 0156\tAverage Loss: 0.35\tAccuracy: 0.872\n",
            "Step 0157\tAverage Loss: 0.58\tAccuracy: 0.877\n",
            "Step 0158\tAverage Loss: 0.56\tAccuracy: 0.869\n",
            "Step 0159\tAverage Loss: 0.63\tAccuracy: 0.873\n",
            "Step 0160\tAverage Loss: 0.53\tAccuracy: 0.872\n",
            "Step 0161\tAverage Loss: 0.32\tAccuracy: 0.872\n",
            "Step 0162\tAverage Loss: 0.44\tAccuracy: 0.873\n",
            "Step 0163\tAverage Loss: 0.34\tAccuracy: 0.868\n",
            "Step 0164\tAverage Loss: 0.32\tAccuracy: 0.865\n",
            "Step 0165\tAverage Loss: 0.51\tAccuracy: 0.875\n",
            "Step 0166\tAverage Loss: 0.52\tAccuracy: 0.876\n",
            "Step 0167\tAverage Loss: 0.43\tAccuracy: 0.877\n",
            "Step 0168\tAverage Loss: 0.44\tAccuracy: 0.877\n",
            "Step 0169\tAverage Loss: 0.48\tAccuracy: 0.875\n",
            "Step 0170\tAverage Loss: 0.44\tAccuracy: 0.877\n",
            "Step 0171\tAverage Loss: 0.48\tAccuracy: 0.873\n",
            "Step 0172\tAverage Loss: 0.56\tAccuracy: 0.879\n",
            "Step 0173\tAverage Loss: 0.21\tAccuracy: 0.873\n",
            "Step 0174\tAverage Loss: 0.60\tAccuracy: 0.871\n",
            "Step 0175\tAverage Loss: 0.70\tAccuracy: 0.871\n",
            "Step 0176\tAverage Loss: 0.51\tAccuracy: 0.872\n",
            "Step 0177\tAverage Loss: 0.49\tAccuracy: 0.871\n",
            "Step 0178\tAverage Loss: 0.56\tAccuracy: 0.881\n",
            "Step 0179\tAverage Loss: 0.32\tAccuracy: 0.878\n",
            "Step 0180\tAverage Loss: 0.39\tAccuracy: 0.876\n",
            "Step 0181\tAverage Loss: 0.36\tAccuracy: 0.881\n",
            "Step 0182\tAverage Loss: 0.34\tAccuracy: 0.873\n",
            "Step 0183\tAverage Loss: 0.28\tAccuracy: 0.879\n",
            "Step 0184\tAverage Loss: 0.43\tAccuracy: 0.866\n",
            "Step 0185\tAverage Loss: 0.40\tAccuracy: 0.877\n",
            "Step 0186\tAverage Loss: 0.37\tAccuracy: 0.879\n",
            "Step 0187\tAverage Loss: 0.31\tAccuracy: 0.880\n",
            "Step 0188\tAverage Loss: 0.38\tAccuracy: 0.882\n",
            "Step 0189\tAverage Loss: 0.35\tAccuracy: 0.882\n",
            "Step 0190\tAverage Loss: 0.44\tAccuracy: 0.879\n",
            "Step 0191\tAverage Loss: 0.38\tAccuracy: 0.882\n",
            "Step 0192\tAverage Loss: 0.49\tAccuracy: 0.881\n",
            "Step 0193\tAverage Loss: 0.43\tAccuracy: 0.881\n",
            "Step 0194\tAverage Loss: 0.31\tAccuracy: 0.882\n",
            "Step 0195\tAverage Loss: 0.45\tAccuracy: 0.868\n",
            "Step 0196\tAverage Loss: 0.24\tAccuracy: 0.881\n",
            "Step 0197\tAverage Loss: 0.20\tAccuracy: 0.880\n",
            "Step 0198\tAverage Loss: 0.49\tAccuracy: 0.875\n",
            "Step 0199\tAverage Loss: 0.45\tAccuracy: 0.867\n",
            "Step 0200\tAverage Loss: 0.60\tAccuracy: 0.873\n",
            "Step 0201\tAverage Loss: 0.53\tAccuracy: 0.878\n",
            "Step 0202\tAverage Loss: 0.43\tAccuracy: 0.878\n",
            "Step 0203\tAverage Loss: 0.34\tAccuracy: 0.884\n",
            "Step 0204\tAverage Loss: 0.20\tAccuracy: 0.884\n",
            "Step 0205\tAverage Loss: 0.45\tAccuracy: 0.884\n",
            "Step 0206\tAverage Loss: 0.38\tAccuracy: 0.880\n",
            "Step 0207\tAverage Loss: 0.51\tAccuracy: 0.868\n",
            "Step 0208\tAverage Loss: 0.51\tAccuracy: 0.866\n",
            "Step 0209\tAverage Loss: 0.80\tAccuracy: 0.871\n",
            "Step 0210\tAverage Loss: 0.49\tAccuracy: 0.881\n",
            "Step 0211\tAverage Loss: 0.40\tAccuracy: 0.880\n",
            "Step 0212\tAverage Loss: 0.23\tAccuracy: 0.884\n",
            "Step 0213\tAverage Loss: 0.42\tAccuracy: 0.879\n",
            "Step 0214\tAverage Loss: 0.28\tAccuracy: 0.881\n",
            "Step 0215\tAverage Loss: 0.41\tAccuracy: 0.880\n",
            "Step 0216\tAverage Loss: 0.39\tAccuracy: 0.884\n",
            "Step 0217\tAverage Loss: 0.26\tAccuracy: 0.886\n",
            "Step 0218\tAverage Loss: 0.25\tAccuracy: 0.887\n",
            "Step 0219\tAverage Loss: 0.42\tAccuracy: 0.885\n",
            "Step 0220\tAverage Loss: 0.24\tAccuracy: 0.884\n",
            "Step 0221\tAverage Loss: 0.49\tAccuracy: 0.881\n",
            "Step 0222\tAverage Loss: 0.56\tAccuracy: 0.883\n",
            "Step 0223\tAverage Loss: 0.24\tAccuracy: 0.882\n",
            "Step 0224\tAverage Loss: 0.53\tAccuracy: 0.885\n",
            "Step 0225\tAverage Loss: 0.96\tAccuracy: 0.877\n",
            "Step 0226\tAverage Loss: 0.38\tAccuracy: 0.868\n",
            "Step 0227\tAverage Loss: 0.42\tAccuracy: 0.875\n",
            "Step 0228\tAverage Loss: 0.25\tAccuracy: 0.877\n",
            "Step 0229\tAverage Loss: 0.26\tAccuracy: 0.874\n",
            "Step 0230\tAverage Loss: 0.47\tAccuracy: 0.888\n",
            "Step 0231\tAverage Loss: 0.35\tAccuracy: 0.888\n",
            "Step 0232\tAverage Loss: 0.35\tAccuracy: 0.887\n",
            "Step 0233\tAverage Loss: 0.33\tAccuracy: 0.886\n",
            "Step 0234\tAverage Loss: 0.39\tAccuracy: 0.883\n",
            "Step 0235\tAverage Loss: 0.34\tAccuracy: 0.887\n",
            "Step 0236\tAverage Loss: 0.35\tAccuracy: 0.875\n",
            "Step 0237\tAverage Loss: 0.45\tAccuracy: 0.889\n",
            "Step 0238\tAverage Loss: 0.48\tAccuracy: 0.886\n",
            "Step 0239\tAverage Loss: 0.42\tAccuracy: 0.883\n",
            "Step 0240\tAverage Loss: 0.42\tAccuracy: 0.886\n",
            "Step 0241\tAverage Loss: 0.33\tAccuracy: 0.886\n",
            "Step 0242\tAverage Loss: 0.55\tAccuracy: 0.883\n",
            "Step 0243\tAverage Loss: 0.33\tAccuracy: 0.887\n",
            "Step 0244\tAverage Loss: 0.39\tAccuracy: 0.890\n",
            "Step 0245\tAverage Loss: 0.40\tAccuracy: 0.883\n",
            "Step 0246\tAverage Loss: 0.48\tAccuracy: 0.885\n",
            "Step 0247\tAverage Loss: 0.62\tAccuracy: 0.876\n",
            "Step 0248\tAverage Loss: 0.39\tAccuracy: 0.891\n",
            "Step 0249\tAverage Loss: 0.46\tAccuracy: 0.890\n",
            "Step 0250\tAverage Loss: 0.28\tAccuracy: 0.888\n",
            "Step 0251\tAverage Loss: 0.34\tAccuracy: 0.885\n",
            "Step 0252\tAverage Loss: 0.33\tAccuracy: 0.888\n",
            "Step 0253\tAverage Loss: 0.36\tAccuracy: 0.890\n",
            "Step 0254\tAverage Loss: 0.28\tAccuracy: 0.885\n",
            "Step 0255\tAverage Loss: 0.30\tAccuracy: 0.887\n",
            "Step 0256\tAverage Loss: 0.30\tAccuracy: 0.885\n",
            "Step 0257\tAverage Loss: 0.28\tAccuracy: 0.891\n",
            "Step 0258\tAverage Loss: 0.36\tAccuracy: 0.891\n",
            "Step 0259\tAverage Loss: 0.32\tAccuracy: 0.891\n",
            "Step 0260\tAverage Loss: 0.26\tAccuracy: 0.887\n",
            "Step 0261\tAverage Loss: 0.24\tAccuracy: 0.890\n",
            "Step 0262\tAverage Loss: 0.30\tAccuracy: 0.891\n",
            "Step 0263\tAverage Loss: 0.55\tAccuracy: 0.891\n",
            "Step 0264\tAverage Loss: 0.40\tAccuracy: 0.891\n",
            "Step 0265\tAverage Loss: 0.43\tAccuracy: 0.891\n",
            "Step 0266\tAverage Loss: 0.57\tAccuracy: 0.891\n",
            "Step 0267\tAverage Loss: 0.53\tAccuracy: 0.882\n",
            "Step 0268\tAverage Loss: 0.48\tAccuracy: 0.889\n",
            "Step 0269\tAverage Loss: 0.29\tAccuracy: 0.889\n",
            "Step 0270\tAverage Loss: 0.25\tAccuracy: 0.884\n",
            "Step 0271\tAverage Loss: 0.57\tAccuracy: 0.883\n",
            "Step 0272\tAverage Loss: 0.47\tAccuracy: 0.871\n",
            "Step 0273\tAverage Loss: 0.27\tAccuracy: 0.881\n",
            "Step 0274\tAverage Loss: 0.40\tAccuracy: 0.883\n",
            "Step 0275\tAverage Loss: 0.36\tAccuracy: 0.887\n",
            "Step 0276\tAverage Loss: 0.44\tAccuracy: 0.891\n",
            "Step 0277\tAverage Loss: 0.47\tAccuracy: 0.890\n",
            "Step 0278\tAverage Loss: 0.36\tAccuracy: 0.887\n",
            "Step 0279\tAverage Loss: 0.27\tAccuracy: 0.888\n",
            "Step 0280\tAverage Loss: 0.23\tAccuracy: 0.890\n",
            "Step 0281\tAverage Loss: 0.49\tAccuracy: 0.886\n",
            "Step 0282\tAverage Loss: 0.24\tAccuracy: 0.878\n",
            "Step 0283\tAverage Loss: 0.60\tAccuracy: 0.890\n",
            "Step 0284\tAverage Loss: 0.31\tAccuracy: 0.890\n",
            "Step 0285\tAverage Loss: 0.31\tAccuracy: 0.890\n",
            "Step 0286\tAverage Loss: 0.81\tAccuracy: 0.888\n",
            "Step 0287\tAverage Loss: 0.38\tAccuracy: 0.887\n",
            "Step 0288\tAverage Loss: 0.23\tAccuracy: 0.891\n",
            "Step 0289\tAverage Loss: 0.30\tAccuracy: 0.892\n",
            "Step 0290\tAverage Loss: 0.34\tAccuracy: 0.894\n",
            "Step 0291\tAverage Loss: 0.50\tAccuracy: 0.891\n",
            "Step 0292\tAverage Loss: 0.45\tAccuracy: 0.891\n",
            "Step 0293\tAverage Loss: 0.38\tAccuracy: 0.888\n",
            "Step 0294\tAverage Loss: 0.32\tAccuracy: 0.892\n",
            "Step 0295\tAverage Loss: 0.33\tAccuracy: 0.888\n",
            "Step 0296\tAverage Loss: 0.34\tAccuracy: 0.892\n",
            "Step 0297\tAverage Loss: 0.51\tAccuracy: 0.889\n",
            "Step 0298\tAverage Loss: 0.55\tAccuracy: 0.891\n",
            "Step 0299\tAverage Loss: 0.67\tAccuracy: 0.888\n",
            "Step 0300\tAverage Loss: 0.44\tAccuracy: 0.887\n",
            "Step 0301\tAverage Loss: 0.64\tAccuracy: 0.890\n",
            "Step 0302\tAverage Loss: 0.34\tAccuracy: 0.892\n",
            "Step 0303\tAverage Loss: 0.33\tAccuracy: 0.892\n",
            "Step 0304\tAverage Loss: 0.39\tAccuracy: 0.895\n",
            "Step 0305\tAverage Loss: 0.40\tAccuracy: 0.893\n",
            "Step 0306\tAverage Loss: 0.63\tAccuracy: 0.893\n",
            "Step 0307\tAverage Loss: 0.31\tAccuracy: 0.894\n",
            "Step 0308\tAverage Loss: 0.57\tAccuracy: 0.885\n",
            "Step 0309\tAverage Loss: 0.33\tAccuracy: 0.881\n",
            "Step 0310\tAverage Loss: 0.40\tAccuracy: 0.893\n",
            "Step 0311\tAverage Loss: 0.70\tAccuracy: 0.894\n",
            "Step 0312\tAverage Loss: 0.47\tAccuracy: 0.891\n",
            "Step 0313\tAverage Loss: 0.72\tAccuracy: 0.896\n",
            "Step 0314\tAverage Loss: 0.41\tAccuracy: 0.898\n",
            "Step 0315\tAverage Loss: 0.30\tAccuracy: 0.889\n",
            "Step 0316\tAverage Loss: 0.48\tAccuracy: 0.895\n",
            "Step 0317\tAverage Loss: 0.71\tAccuracy: 0.891\n",
            "Step 0318\tAverage Loss: 0.43\tAccuracy: 0.891\n",
            "Step 0319\tAverage Loss: 0.33\tAccuracy: 0.892\n",
            "Step 0320\tAverage Loss: 0.38\tAccuracy: 0.891\n",
            "Step 0321\tAverage Loss: 0.52\tAccuracy: 0.891\n",
            "Step 0322\tAverage Loss: 0.56\tAccuracy: 0.892\n",
            "Step 0323\tAverage Loss: 0.52\tAccuracy: 0.864\n",
            "Step 0324\tAverage Loss: 0.60\tAccuracy: 0.888\n",
            "Step 0325\tAverage Loss: 0.34\tAccuracy: 0.889\n",
            "Step 0326\tAverage Loss: 0.39\tAccuracy: 0.894\n",
            "Step 0327\tAverage Loss: 0.50\tAccuracy: 0.893\n",
            "Step 0328\tAverage Loss: 0.34\tAccuracy: 0.893\n",
            "Step 0329\tAverage Loss: 0.35\tAccuracy: 0.896\n",
            "Step 0330\tAverage Loss: 0.33\tAccuracy: 0.894\n",
            "Step 0331\tAverage Loss: 0.26\tAccuracy: 0.890\n",
            "Step 0332\tAverage Loss: 0.43\tAccuracy: 0.894\n",
            "Step 0333\tAverage Loss: 0.48\tAccuracy: 0.894\n",
            "Step 0334\tAverage Loss: 0.39\tAccuracy: 0.893\n",
            "Step 0335\tAverage Loss: 0.40\tAccuracy: 0.894\n",
            "Step 0336\tAverage Loss: 0.26\tAccuracy: 0.897\n",
            "Step 0337\tAverage Loss: 0.30\tAccuracy: 0.893\n",
            "Step 0338\tAverage Loss: 0.14\tAccuracy: 0.895\n",
            "Step 0339\tAverage Loss: 0.19\tAccuracy: 0.897\n",
            "Step 0340\tAverage Loss: 0.32\tAccuracy: 0.896\n",
            "Step 0341\tAverage Loss: 0.22\tAccuracy: 0.895\n",
            "Step 0342\tAverage Loss: 0.23\tAccuracy: 0.897\n",
            "Step 0343\tAverage Loss: 0.25\tAccuracy: 0.896\n",
            "Step 0344\tAverage Loss: 0.50\tAccuracy: 0.893\n",
            "Step 0345\tAverage Loss: 0.54\tAccuracy: 0.879\n",
            "Step 0346\tAverage Loss: 0.53\tAccuracy: 0.895\n",
            "Step 0347\tAverage Loss: 0.38\tAccuracy: 0.893\n",
            "Step 0348\tAverage Loss: 0.64\tAccuracy: 0.894\n",
            "Step 0349\tAverage Loss: 0.38\tAccuracy: 0.899\n",
            "Step 0350\tAverage Loss: 0.29\tAccuracy: 0.896\n",
            "Step 0351\tAverage Loss: 0.34\tAccuracy: 0.896\n",
            "Step 0352\tAverage Loss: 0.32\tAccuracy: 0.897\n",
            "Step 0353\tAverage Loss: 0.27\tAccuracy: 0.895\n",
            "Step 0354\tAverage Loss: 0.48\tAccuracy: 0.895\n",
            "Step 0355\tAverage Loss: 0.22\tAccuracy: 0.889\n",
            "Step 0356\tAverage Loss: 0.42\tAccuracy: 0.887\n",
            "Step 0357\tAverage Loss: 0.25\tAccuracy: 0.898\n",
            "Step 0358\tAverage Loss: 0.24\tAccuracy: 0.897\n",
            "Step 0359\tAverage Loss: 0.37\tAccuracy: 0.896\n",
            "Step 0360\tAverage Loss: 0.47\tAccuracy: 0.891\n",
            "Step 0361\tAverage Loss: 0.36\tAccuracy: 0.897\n",
            "Step 0362\tAverage Loss: 0.25\tAccuracy: 0.896\n",
            "Step 0363\tAverage Loss: 0.27\tAccuracy: 0.896\n",
            "Step 0364\tAverage Loss: 0.47\tAccuracy: 0.891\n",
            "Step 0365\tAverage Loss: 0.19\tAccuracy: 0.891\n",
            "Step 0366\tAverage Loss: 0.13\tAccuracy: 0.895\n",
            "Step 0367\tAverage Loss: 0.41\tAccuracy: 0.895\n",
            "Step 0368\tAverage Loss: 0.37\tAccuracy: 0.894\n",
            "Step 0369\tAverage Loss: 0.25\tAccuracy: 0.891\n",
            "Step 0370\tAverage Loss: 0.46\tAccuracy: 0.893\n",
            "Step 0371\tAverage Loss: 0.44\tAccuracy: 0.891\n",
            "Step 0372\tAverage Loss: 0.49\tAccuracy: 0.888\n",
            "Step 0373\tAverage Loss: 0.91\tAccuracy: 0.885\n",
            "Step 0374\tAverage Loss: 0.84\tAccuracy: 0.889\n",
            "Step 0375\tAverage Loss: 0.50\tAccuracy: 0.881\n",
            "Step 0376\tAverage Loss: 0.35\tAccuracy: 0.894\n",
            "Step 0377\tAverage Loss: 0.39\tAccuracy: 0.896\n",
            "Step 0378\tAverage Loss: 0.36\tAccuracy: 0.896\n",
            "Step 0379\tAverage Loss: 0.43\tAccuracy: 0.896\n",
            "Step 0380\tAverage Loss: 0.34\tAccuracy: 0.896\n",
            "Step 0381\tAverage Loss: 0.20\tAccuracy: 0.894\n",
            "Step 0382\tAverage Loss: 0.42\tAccuracy: 0.899\n",
            "Step 0383\tAverage Loss: 0.40\tAccuracy: 0.891\n",
            "Step 0384\tAverage Loss: 0.24\tAccuracy: 0.895\n",
            "Step 0385\tAverage Loss: 0.58\tAccuracy: 0.896\n",
            "Step 0386\tAverage Loss: 0.46\tAccuracy: 0.895\n",
            "Step 0387\tAverage Loss: 0.31\tAccuracy: 0.900\n",
            "Step 0388\tAverage Loss: 0.16\tAccuracy: 0.898\n",
            "Step 0389\tAverage Loss: 0.22\tAccuracy: 0.899\n",
            "Step 0390\tAverage Loss: 0.26\tAccuracy: 0.900\n",
            "Step 0391\tAverage Loss: 0.34\tAccuracy: 0.900\n",
            "Step 0392\tAverage Loss: 0.32\tAccuracy: 0.898\n",
            "Step 0393\tAverage Loss: 0.67\tAccuracy: 0.886\n",
            "Step 0394\tAverage Loss: 0.74\tAccuracy: 0.879\n",
            "Step 0395\tAverage Loss: 0.32\tAccuracy: 0.898\n",
            "Step 0396\tAverage Loss: 0.44\tAccuracy: 0.894\n",
            "Step 0397\tAverage Loss: 0.42\tAccuracy: 0.898\n",
            "Step 0398\tAverage Loss: 0.34\tAccuracy: 0.890\n",
            "Step 0399\tAverage Loss: 0.44\tAccuracy: 0.895\n",
            "Step 0400\tAverage Loss: 0.32\tAccuracy: 0.895\n",
            "Step 0401\tAverage Loss: 0.34\tAccuracy: 0.898\n",
            "Step 0402\tAverage Loss: 0.27\tAccuracy: 0.899\n",
            "Step 0403\tAverage Loss: 0.30\tAccuracy: 0.898\n",
            "Step 0404\tAverage Loss: 0.38\tAccuracy: 0.898\n",
            "Step 0405\tAverage Loss: 0.38\tAccuracy: 0.899\n",
            "Step 0406\tAverage Loss: 0.26\tAccuracy: 0.900\n",
            "Step 0407\tAverage Loss: 0.35\tAccuracy: 0.899\n",
            "Step 0408\tAverage Loss: 0.22\tAccuracy: 0.897\n",
            "Step 0409\tAverage Loss: 0.31\tAccuracy: 0.898\n",
            "Step 0410\tAverage Loss: 0.45\tAccuracy: 0.900\n",
            "Step 0411\tAverage Loss: 0.27\tAccuracy: 0.899\n",
            "Step 0412\tAverage Loss: 0.48\tAccuracy: 0.900\n",
            "Step 0413\tAverage Loss: 0.40\tAccuracy: 0.895\n",
            "Step 0414\tAverage Loss: 0.58\tAccuracy: 0.898\n",
            "Step 0415\tAverage Loss: 0.49\tAccuracy: 0.895\n",
            "Step 0416\tAverage Loss: 0.26\tAccuracy: 0.898\n",
            "Step 0417\tAverage Loss: 0.28\tAccuracy: 0.897\n",
            "Step 0418\tAverage Loss: 0.35\tAccuracy: 0.898\n",
            "Step 0419\tAverage Loss: 0.40\tAccuracy: 0.898\n",
            "Step 0420\tAverage Loss: 0.42\tAccuracy: 0.898\n",
            "Step 0421\tAverage Loss: 0.49\tAccuracy: 0.878\n",
            "Step 0422\tAverage Loss: 0.31\tAccuracy: 0.870\n",
            "Step 0423\tAverage Loss: 0.69\tAccuracy: 0.895\n",
            "Step 0424\tAverage Loss: 0.57\tAccuracy: 0.900\n",
            "Step 0425\tAverage Loss: 0.47\tAccuracy: 0.891\n",
            "Step 0426\tAverage Loss: 0.26\tAccuracy: 0.896\n",
            "Step 0427\tAverage Loss: 0.38\tAccuracy: 0.896\n",
            "Step 0428\tAverage Loss: 0.42\tAccuracy: 0.896\n",
            "Step 0429\tAverage Loss: 0.46\tAccuracy: 0.897\n",
            "Step 0430\tAverage Loss: 0.41\tAccuracy: 0.894\n",
            "Step 0431\tAverage Loss: 0.30\tAccuracy: 0.897\n",
            "Step 0432\tAverage Loss: 0.39\tAccuracy: 0.898\n",
            "Step 0433\tAverage Loss: 0.19\tAccuracy: 0.898\n",
            "Step 0434\tAverage Loss: 0.16\tAccuracy: 0.898\n",
            "Step 0435\tAverage Loss: 0.36\tAccuracy: 0.897\n",
            "Step 0436\tAverage Loss: 0.31\tAccuracy: 0.897\n",
            "Step 0437\tAverage Loss: 0.26\tAccuracy: 0.891\n",
            "Step 0438\tAverage Loss: 0.45\tAccuracy: 0.894\n",
            "Step 0439\tAverage Loss: 0.49\tAccuracy: 0.898\n",
            "Step 0440\tAverage Loss: 0.27\tAccuracy: 0.902\n",
            "Step 0441\tAverage Loss: 0.43\tAccuracy: 0.900\n",
            "Step 0442\tAverage Loss: 0.38\tAccuracy: 0.901\n",
            "Step 0443\tAverage Loss: 0.48\tAccuracy: 0.900\n",
            "Step 0444\tAverage Loss: 0.47\tAccuracy: 0.900\n",
            "Step 0445\tAverage Loss: 0.20\tAccuracy: 0.900\n",
            "Step 0446\tAverage Loss: 0.21\tAccuracy: 0.900\n",
            "Step 0447\tAverage Loss: 0.34\tAccuracy: 0.901\n",
            "Step 0448\tAverage Loss: 0.51\tAccuracy: 0.901\n",
            "Step 0449\tAverage Loss: 0.43\tAccuracy: 0.895\n",
            "Step 0450\tAverage Loss: 0.54\tAccuracy: 0.891\n",
            "Step 0451\tAverage Loss: 0.40\tAccuracy: 0.894\n",
            "Step 0452\tAverage Loss: 0.26\tAccuracy: 0.891\n",
            "Step 0453\tAverage Loss: 0.23\tAccuracy: 0.897\n",
            "Step 0454\tAverage Loss: 0.54\tAccuracy: 0.901\n",
            "Step 0455\tAverage Loss: 0.48\tAccuracy: 0.900\n",
            "Step 0456\tAverage Loss: 0.41\tAccuracy: 0.898\n",
            "Step 0457\tAverage Loss: 0.35\tAccuracy: 0.901\n",
            "Step 0458\tAverage Loss: 0.52\tAccuracy: 0.900\n",
            "Step 0459\tAverage Loss: 0.46\tAccuracy: 0.900\n",
            "Step 0460\tAverage Loss: 0.51\tAccuracy: 0.902\n",
            "Step 0461\tAverage Loss: 0.42\tAccuracy: 0.898\n",
            "Step 0462\tAverage Loss: 0.73\tAccuracy: 0.900\n",
            "Step 0463\tAverage Loss: 0.47\tAccuracy: 0.903\n",
            "Step 0464\tAverage Loss: 0.46\tAccuracy: 0.902\n",
            "Step 0465\tAverage Loss: 0.17\tAccuracy: 0.900\n",
            "Step 0466\tAverage Loss: 0.26\tAccuracy: 0.887\n",
            "Step 0467\tAverage Loss: 0.37\tAccuracy: 0.900\n",
            "Step 0468\tAverage Loss: 0.25\tAccuracy: 0.894\n",
            "Step 0469\tAverage Loss: 0.31\tAccuracy: 0.896\n",
            "Step 0470\tAverage Loss: 0.29\tAccuracy: 0.899\n",
            "Step 0471\tAverage Loss: 0.25\tAccuracy: 0.899\n",
            "Step 0472\tAverage Loss: 0.46\tAccuracy: 0.899\n",
            "Step 0473\tAverage Loss: 0.35\tAccuracy: 0.899\n",
            "Step 0474\tAverage Loss: 0.41\tAccuracy: 0.897\n",
            "Step 0475\tAverage Loss: 0.39\tAccuracy: 0.895\n",
            "Step 0476\tAverage Loss: 0.53\tAccuracy: 0.897\n",
            "Step 0477\tAverage Loss: 0.43\tAccuracy: 0.903\n",
            "Step 0478\tAverage Loss: 0.17\tAccuracy: 0.901\n",
            "Step 0479\tAverage Loss: 0.49\tAccuracy: 0.897\n",
            "Step 0480\tAverage Loss: 0.28\tAccuracy: 0.897\n",
            "Step 0481\tAverage Loss: 0.20\tAccuracy: 0.900\n",
            "Step 0482\tAverage Loss: 0.18\tAccuracy: 0.903\n",
            "Step 0483\tAverage Loss: 0.58\tAccuracy: 0.899\n",
            "Step 0484\tAverage Loss: 0.17\tAccuracy: 0.903\n",
            "Step 0485\tAverage Loss: 0.36\tAccuracy: 0.901\n",
            "Step 0486\tAverage Loss: 0.23\tAccuracy: 0.900\n",
            "Step 0487\tAverage Loss: 0.19\tAccuracy: 0.901\n",
            "Step 0488\tAverage Loss: 0.27\tAccuracy: 0.904\n",
            "Step 0489\tAverage Loss: 0.58\tAccuracy: 0.889\n",
            "Step 0490\tAverage Loss: 0.60\tAccuracy: 0.894\n",
            "Step 0491\tAverage Loss: 0.28\tAccuracy: 0.898\n",
            "Step 0492\tAverage Loss: 0.41\tAccuracy: 0.900\n",
            "Step 0493\tAverage Loss: 0.26\tAccuracy: 0.903\n",
            "Step 0494\tAverage Loss: 0.51\tAccuracy: 0.902\n",
            "Step 0495\tAverage Loss: 0.73\tAccuracy: 0.899\n",
            "Step 0496\tAverage Loss: 0.60\tAccuracy: 0.902\n",
            "Step 0497\tAverage Loss: 0.25\tAccuracy: 0.899\n",
            "Step 0498\tAverage Loss: 0.58\tAccuracy: 0.899\n",
            "Step 0499\tAverage Loss: 0.28\tAccuracy: 0.896\n",
            "Step 0500\tAverage Loss: 0.41\tAccuracy: 0.899\n",
            "Step 0501\tAverage Loss: 0.30\tAccuracy: 0.899\n",
            "Step 0502\tAverage Loss: 0.58\tAccuracy: 0.897\n",
            "Step 0503\tAverage Loss: 0.61\tAccuracy: 0.901\n",
            "Step 0504\tAverage Loss: 0.60\tAccuracy: 0.898\n",
            "Step 0505\tAverage Loss: 0.46\tAccuracy: 0.905\n",
            "Step 0506\tAverage Loss: 0.32\tAccuracy: 0.904\n",
            "Step 0507\tAverage Loss: 0.35\tAccuracy: 0.898\n",
            "Step 0508\tAverage Loss: 0.35\tAccuracy: 0.896\n",
            "Step 0509\tAverage Loss: 0.16\tAccuracy: 0.901\n",
            "Step 0510\tAverage Loss: 0.18\tAccuracy: 0.902\n",
            "Step 0511\tAverage Loss: 0.38\tAccuracy: 0.901\n",
            "Step 0512\tAverage Loss: 0.46\tAccuracy: 0.892\n",
            "Step 0513\tAverage Loss: 0.30\tAccuracy: 0.897\n",
            "Step 0514\tAverage Loss: 0.22\tAccuracy: 0.901\n",
            "Step 0515\tAverage Loss: 0.23\tAccuracy: 0.902\n",
            "Step 0516\tAverage Loss: 0.28\tAccuracy: 0.904\n",
            "Step 0517\tAverage Loss: 0.36\tAccuracy: 0.903\n",
            "Step 0518\tAverage Loss: 0.20\tAccuracy: 0.902\n",
            "Step 0519\tAverage Loss: 0.49\tAccuracy: 0.901\n",
            "Step 0520\tAverage Loss: 0.45\tAccuracy: 0.905\n",
            "Step 0521\tAverage Loss: 0.58\tAccuracy: 0.905\n",
            "Step 0522\tAverage Loss: 0.41\tAccuracy: 0.901\n",
            "Step 0523\tAverage Loss: 0.48\tAccuracy: 0.900\n",
            "Step 0524\tAverage Loss: 0.20\tAccuracy: 0.905\n",
            "Step 0525\tAverage Loss: 0.21\tAccuracy: 0.907\n",
            "Step 0526\tAverage Loss: 0.37\tAccuracy: 0.907\n",
            "Step 0527\tAverage Loss: 0.38\tAccuracy: 0.904\n",
            "Step 0528\tAverage Loss: 0.60\tAccuracy: 0.903\n",
            "Step 0529\tAverage Loss: 0.72\tAccuracy: 0.899\n",
            "Step 0530\tAverage Loss: 0.34\tAccuracy: 0.904\n",
            "Step 0531\tAverage Loss: 0.41\tAccuracy: 0.899\n",
            "Step 0532\tAverage Loss: 0.32\tAccuracy: 0.904\n",
            "Step 0533\tAverage Loss: 0.14\tAccuracy: 0.906\n",
            "Step 0534\tAverage Loss: 0.20\tAccuracy: 0.906\n",
            "Step 0535\tAverage Loss: 0.48\tAccuracy: 0.903\n",
            "Step 0536\tAverage Loss: 0.31\tAccuracy: 0.900\n",
            "Step 0537\tAverage Loss: 0.26\tAccuracy: 0.903\n",
            "Step 0538\tAverage Loss: 0.34\tAccuracy: 0.900\n",
            "Step 0539\tAverage Loss: 0.50\tAccuracy: 0.899\n",
            "Step 0540\tAverage Loss: 0.43\tAccuracy: 0.903\n",
            "Step 0541\tAverage Loss: 0.34\tAccuracy: 0.905\n",
            "Step 0542\tAverage Loss: 0.25\tAccuracy: 0.908\n",
            "Step 0543\tAverage Loss: 0.29\tAccuracy: 0.906\n",
            "Step 0544\tAverage Loss: 0.24\tAccuracy: 0.901\n",
            "Step 0545\tAverage Loss: 0.48\tAccuracy: 0.902\n",
            "Step 0546\tAverage Loss: 0.23\tAccuracy: 0.907\n",
            "Step 0547\tAverage Loss: 0.18\tAccuracy: 0.904\n",
            "Step 0548\tAverage Loss: 0.42\tAccuracy: 0.900\n",
            "Step 0549\tAverage Loss: 0.65\tAccuracy: 0.899\n",
            "Step 0550\tAverage Loss: 0.27\tAccuracy: 0.904\n",
            "Step 0551\tAverage Loss: 0.34\tAccuracy: 0.900\n",
            "Step 0552\tAverage Loss: 0.22\tAccuracy: 0.900\n",
            "Step 0553\tAverage Loss: 0.38\tAccuracy: 0.903\n",
            "Step 0554\tAverage Loss: 0.21\tAccuracy: 0.904\n",
            "Step 0555\tAverage Loss: 0.32\tAccuracy: 0.903\n",
            "Step 0556\tAverage Loss: 0.25\tAccuracy: 0.904\n",
            "Step 0557\tAverage Loss: 0.42\tAccuracy: 0.903\n",
            "Step 0558\tAverage Loss: 0.31\tAccuracy: 0.899\n",
            "Step 0559\tAverage Loss: 0.18\tAccuracy: 0.903\n",
            "Step 0560\tAverage Loss: 0.26\tAccuracy: 0.905\n",
            "Step 0561\tAverage Loss: 0.19\tAccuracy: 0.905\n",
            "Step 0562\tAverage Loss: 0.38\tAccuracy: 0.905\n",
            "Step 0563\tAverage Loss: 0.28\tAccuracy: 0.904\n",
            "Step 0564\tAverage Loss: 0.54\tAccuracy: 0.906\n",
            "Step 0565\tAverage Loss: 0.16\tAccuracy: 0.907\n",
            "Step 0566\tAverage Loss: 0.47\tAccuracy: 0.905\n",
            "Step 0567\tAverage Loss: 0.18\tAccuracy: 0.901\n",
            "Step 0568\tAverage Loss: 0.27\tAccuracy: 0.903\n",
            "Step 0569\tAverage Loss: 0.28\tAccuracy: 0.901\n",
            "Step 0570\tAverage Loss: 0.31\tAccuracy: 0.901\n",
            "Step 0571\tAverage Loss: 0.17\tAccuracy: 0.907\n",
            "Step 0572\tAverage Loss: 0.33\tAccuracy: 0.901\n",
            "Step 0573\tAverage Loss: 0.30\tAccuracy: 0.903\n",
            "Step 0574\tAverage Loss: 0.27\tAccuracy: 0.904\n",
            "Step 0575\tAverage Loss: 0.29\tAccuracy: 0.899\n",
            "Step 0576\tAverage Loss: 0.43\tAccuracy: 0.902\n",
            "Step 0577\tAverage Loss: 0.43\tAccuracy: 0.899\n",
            "Step 0578\tAverage Loss: 0.24\tAccuracy: 0.906\n",
            "Step 0579\tAverage Loss: 0.22\tAccuracy: 0.905\n",
            "Step 0580\tAverage Loss: 0.27\tAccuracy: 0.906\n",
            "Step 0581\tAverage Loss: 0.21\tAccuracy: 0.905\n",
            "Step 0582\tAverage Loss: 0.18\tAccuracy: 0.904\n",
            "Step 0583\tAverage Loss: 0.15\tAccuracy: 0.903\n",
            "Step 0584\tAverage Loss: 0.23\tAccuracy: 0.894\n",
            "Step 0585\tAverage Loss: 0.28\tAccuracy: 0.905\n",
            "Step 0586\tAverage Loss: 0.19\tAccuracy: 0.908\n",
            "Step 0587\tAverage Loss: 0.19\tAccuracy: 0.904\n",
            "Step 0588\tAverage Loss: 0.27\tAccuracy: 0.905\n",
            "Step 0589\tAverage Loss: 0.03\tAccuracy: 0.906\n",
            "Step 0590\tAverage Loss: 0.08\tAccuracy: 0.907\n",
            "Step 0591\tAverage Loss: 0.08\tAccuracy: 0.906\n",
            "Step 0592\tAverage Loss: 0.24\tAccuracy: 0.903\n",
            "Step 0593\tAverage Loss: 0.44\tAccuracy: 0.903\n",
            "Step 0594\tAverage Loss: 0.37\tAccuracy: 0.893\n",
            "Step 0595\tAverage Loss: 0.10\tAccuracy: 0.893\n",
            "Step 0596\tAverage Loss: 0.18\tAccuracy: 0.897\n",
            "Step 0597\tAverage Loss: 0.79\tAccuracy: 0.890\n",
            "Step 0598\tAverage Loss: 0.04\tAccuracy: 0.892\n",
            "Step 0599\tAverage Loss: 0.39\tAccuracy: 0.898\n",
            "Step 0600\tAverage Loss: 0.26\tAccuracy: 0.897\n",
            "Step 0601\tAverage Loss: 0.37\tAccuracy: 0.901\n",
            "Step 0602\tAverage Loss: 0.45\tAccuracy: 0.901\n",
            "Step 0603\tAverage Loss: 0.14\tAccuracy: 0.902\n",
            "Step 0604\tAverage Loss: 0.33\tAccuracy: 0.905\n",
            "Step 0605\tAverage Loss: 0.39\tAccuracy: 0.906\n",
            "Step 0606\tAverage Loss: 0.51\tAccuracy: 0.905\n",
            "Step 0607\tAverage Loss: 0.36\tAccuracy: 0.907\n",
            "Step 0608\tAverage Loss: 0.56\tAccuracy: 0.908\n",
            "Step 0609\tAverage Loss: 0.36\tAccuracy: 0.905\n",
            "Step 0610\tAverage Loss: 0.62\tAccuracy: 0.906\n",
            "Step 0611\tAverage Loss: 0.48\tAccuracy: 0.905\n",
            "Step 0612\tAverage Loss: 0.45\tAccuracy: 0.902\n",
            "Step 0613\tAverage Loss: 0.53\tAccuracy: 0.896\n",
            "Step 0614\tAverage Loss: 0.23\tAccuracy: 0.903\n",
            "Step 0615\tAverage Loss: 0.42\tAccuracy: 0.903\n",
            "Step 0616\tAverage Loss: 0.22\tAccuracy: 0.905\n",
            "Step 0617\tAverage Loss: 0.17\tAccuracy: 0.907\n",
            "Step 0618\tAverage Loss: 0.21\tAccuracy: 0.906\n",
            "Step 0619\tAverage Loss: 0.20\tAccuracy: 0.908\n",
            "Step 0620\tAverage Loss: 0.44\tAccuracy: 0.908\n",
            "Step 0621\tAverage Loss: 0.19\tAccuracy: 0.909\n",
            "Step 0622\tAverage Loss: 0.21\tAccuracy: 0.904\n",
            "Step 0623\tAverage Loss: 0.20\tAccuracy: 0.904\n",
            "Step 0624\tAverage Loss: 0.29\tAccuracy: 0.893\n",
            "Step 0625\tAverage Loss: 0.14\tAccuracy: 0.897\n",
            "Step 0626\tAverage Loss: 0.40\tAccuracy: 0.901\n",
            "Step 0627\tAverage Loss: 0.35\tAccuracy: 0.905\n",
            "Step 0628\tAverage Loss: 0.28\tAccuracy: 0.906\n",
            "Step 0629\tAverage Loss: 0.21\tAccuracy: 0.902\n",
            "Step 0630\tAverage Loss: 0.42\tAccuracy: 0.894\n",
            "Step 0631\tAverage Loss: 0.22\tAccuracy: 0.906\n",
            "Step 0632\tAverage Loss: 0.39\tAccuracy: 0.908\n",
            "Step 0633\tAverage Loss: 0.29\tAccuracy: 0.907\n",
            "Step 0634\tAverage Loss: 0.19\tAccuracy: 0.905\n",
            "Step 0635\tAverage Loss: 0.34\tAccuracy: 0.904\n",
            "Step 0636\tAverage Loss: 0.39\tAccuracy: 0.905\n",
            "Step 0637\tAverage Loss: 0.39\tAccuracy: 0.906\n",
            "Step 0638\tAverage Loss: 0.18\tAccuracy: 0.906\n",
            "Step 0639\tAverage Loss: 0.15\tAccuracy: 0.906\n",
            "Step 0640\tAverage Loss: 0.36\tAccuracy: 0.907\n",
            "Step 0641\tAverage Loss: 0.48\tAccuracy: 0.909\n",
            "Step 0642\tAverage Loss: 0.29\tAccuracy: 0.906\n",
            "Step 0643\tAverage Loss: 0.28\tAccuracy: 0.908\n",
            "Step 0644\tAverage Loss: 0.22\tAccuracy: 0.908\n",
            "Step 0645\tAverage Loss: 0.21\tAccuracy: 0.907\n",
            "Step 0646\tAverage Loss: 0.38\tAccuracy: 0.908\n",
            "Step 0647\tAverage Loss: 0.29\tAccuracy: 0.906\n",
            "Step 0648\tAverage Loss: 0.27\tAccuracy: 0.905\n",
            "Step 0649\tAverage Loss: 0.39\tAccuracy: 0.908\n",
            "Step 0650\tAverage Loss: 0.32\tAccuracy: 0.906\n",
            "Step 0651\tAverage Loss: 0.61\tAccuracy: 0.907\n",
            "Step 0652\tAverage Loss: 0.22\tAccuracy: 0.909\n",
            "Step 0653\tAverage Loss: 0.42\tAccuracy: 0.909\n",
            "Step 0654\tAverage Loss: 0.16\tAccuracy: 0.909\n",
            "Step 0655\tAverage Loss: 0.31\tAccuracy: 0.908\n",
            "Step 0656\tAverage Loss: 0.30\tAccuracy: 0.908\n",
            "Step 0657\tAverage Loss: 0.29\tAccuracy: 0.905\n",
            "Step 0658\tAverage Loss: 0.34\tAccuracy: 0.907\n",
            "Step 0659\tAverage Loss: 0.26\tAccuracy: 0.906\n",
            "Step 0660\tAverage Loss: 0.17\tAccuracy: 0.907\n",
            "Step 0661\tAverage Loss: 0.27\tAccuracy: 0.904\n",
            "Step 0662\tAverage Loss: 0.26\tAccuracy: 0.903\n",
            "Step 0663\tAverage Loss: 0.19\tAccuracy: 0.902\n",
            "Step 0664\tAverage Loss: 0.36\tAccuracy: 0.903\n",
            "Step 0665\tAverage Loss: 0.16\tAccuracy: 0.906\n",
            "Step 0666\tAverage Loss: 0.26\tAccuracy: 0.907\n",
            "Step 0667\tAverage Loss: 0.25\tAccuracy: 0.900\n",
            "Step 0668\tAverage Loss: 0.48\tAccuracy: 0.904\n",
            "Step 0669\tAverage Loss: 0.39\tAccuracy: 0.899\n",
            "Step 0670\tAverage Loss: 0.42\tAccuracy: 0.907\n",
            "Step 0671\tAverage Loss: 0.32\tAccuracy: 0.907\n",
            "Step 0672\tAverage Loss: 0.45\tAccuracy: 0.908\n",
            "Step 0673\tAverage Loss: 0.36\tAccuracy: 0.904\n",
            "Step 0674\tAverage Loss: 0.20\tAccuracy: 0.908\n",
            "Step 0675\tAverage Loss: 0.29\tAccuracy: 0.909\n",
            "Step 0676\tAverage Loss: 0.33\tAccuracy: 0.908\n",
            "Step 0677\tAverage Loss: 0.31\tAccuracy: 0.902\n",
            "Step 0678\tAverage Loss: 0.55\tAccuracy: 0.905\n",
            "Step 0679\tAverage Loss: 0.29\tAccuracy: 0.902\n",
            "Step 0680\tAverage Loss: 0.27\tAccuracy: 0.904\n",
            "Step 0681\tAverage Loss: 0.33\tAccuracy: 0.900\n",
            "Step 0682\tAverage Loss: 0.55\tAccuracy: 0.901\n",
            "Step 0683\tAverage Loss: 0.20\tAccuracy: 0.910\n",
            "Step 0684\tAverage Loss: 0.55\tAccuracy: 0.905\n",
            "Step 0685\tAverage Loss: 0.23\tAccuracy: 0.906\n",
            "Step 0686\tAverage Loss: 0.49\tAccuracy: 0.899\n",
            "Step 0687\tAverage Loss: 0.74\tAccuracy: 0.905\n",
            "Step 0688\tAverage Loss: 0.55\tAccuracy: 0.894\n",
            "Step 0689\tAverage Loss: 0.30\tAccuracy: 0.899\n",
            "Step 0690\tAverage Loss: 0.21\tAccuracy: 0.903\n",
            "Step 0691\tAverage Loss: 0.36\tAccuracy: 0.904\n",
            "Step 0692\tAverage Loss: 0.35\tAccuracy: 0.906\n",
            "Step 0693\tAverage Loss: 0.42\tAccuracy: 0.903\n",
            "Step 0694\tAverage Loss: 0.45\tAccuracy: 0.901\n",
            "Step 0695\tAverage Loss: 0.38\tAccuracy: 0.898\n",
            "Step 0696\tAverage Loss: 0.24\tAccuracy: 0.901\n",
            "Step 0697\tAverage Loss: 0.31\tAccuracy: 0.905\n",
            "Step 0698\tAverage Loss: 0.18\tAccuracy: 0.905\n",
            "Step 0699\tAverage Loss: 0.16\tAccuracy: 0.906\n",
            "Step 0700\tAverage Loss: 0.33\tAccuracy: 0.909\n",
            "Step 0701\tAverage Loss: 0.22\tAccuracy: 0.907\n",
            "Step 0702\tAverage Loss: 0.59\tAccuracy: 0.839\n",
            "Step 0703\tAverage Loss: 0.25\tAccuracy: 0.868\n",
            "Step 0704\tAverage Loss: 0.27\tAccuracy: 0.894\n",
            "Step 0705\tAverage Loss: 0.16\tAccuracy: 0.901\n",
            "Step 0706\tAverage Loss: 0.19\tAccuracy: 0.902\n",
            "Step 0707\tAverage Loss: 0.45\tAccuracy: 0.903\n",
            "Step 0708\tAverage Loss: 0.28\tAccuracy: 0.905\n",
            "Step 0709\tAverage Loss: 0.25\tAccuracy: 0.905\n",
            "Step 0710\tAverage Loss: 0.22\tAccuracy: 0.907\n",
            "Step 0711\tAverage Loss: 0.19\tAccuracy: 0.907\n",
            "Step 0712\tAverage Loss: 0.35\tAccuracy: 0.903\n",
            "Step 0713\tAverage Loss: 0.19\tAccuracy: 0.904\n",
            "Step 0714\tAverage Loss: 0.29\tAccuracy: 0.907\n",
            "Step 0715\tAverage Loss: 0.51\tAccuracy: 0.906\n",
            "Step 0716\tAverage Loss: 0.37\tAccuracy: 0.906\n",
            "Step 0717\tAverage Loss: 0.56\tAccuracy: 0.899\n",
            "Step 0718\tAverage Loss: 0.31\tAccuracy: 0.900\n",
            "Step 0719\tAverage Loss: 0.22\tAccuracy: 0.899\n",
            "Step 0720\tAverage Loss: 0.33\tAccuracy: 0.900\n",
            "Step 0721\tAverage Loss: 0.31\tAccuracy: 0.892\n",
            "Step 0722\tAverage Loss: 0.36\tAccuracy: 0.897\n",
            "Step 0723\tAverage Loss: 0.40\tAccuracy: 0.905\n",
            "Step 0724\tAverage Loss: 0.34\tAccuracy: 0.903\n",
            "Step 0725\tAverage Loss: 0.61\tAccuracy: 0.899\n",
            "Step 0726\tAverage Loss: 0.67\tAccuracy: 0.895\n",
            "Step 0727\tAverage Loss: 0.35\tAccuracy: 0.905\n",
            "Step 0728\tAverage Loss: 0.19\tAccuracy: 0.906\n",
            "Step 0729\tAverage Loss: 0.52\tAccuracy: 0.906\n",
            "Step 0730\tAverage Loss: 0.64\tAccuracy: 0.905\n",
            "Step 0731\tAverage Loss: 0.40\tAccuracy: 0.905\n",
            "Step 0732\tAverage Loss: 0.25\tAccuracy: 0.904\n",
            "Step 0733\tAverage Loss: 0.31\tAccuracy: 0.907\n",
            "Step 0734\tAverage Loss: 0.23\tAccuracy: 0.908\n",
            "Step 0735\tAverage Loss: 0.26\tAccuracy: 0.908\n",
            "Step 0736\tAverage Loss: 0.38\tAccuracy: 0.908\n",
            "Step 0737\tAverage Loss: 0.37\tAccuracy: 0.910\n",
            "Step 0738\tAverage Loss: 0.31\tAccuracy: 0.908\n",
            "Step 0739\tAverage Loss: 0.54\tAccuracy: 0.912\n",
            "Step 0740\tAverage Loss: 0.45\tAccuracy: 0.910\n",
            "Step 0741\tAverage Loss: 0.40\tAccuracy: 0.903\n",
            "Step 0742\tAverage Loss: 0.39\tAccuracy: 0.908\n",
            "Step 0743\tAverage Loss: 0.60\tAccuracy: 0.907\n",
            "Step 0744\tAverage Loss: 0.27\tAccuracy: 0.910\n",
            "Step 0745\tAverage Loss: 0.42\tAccuracy: 0.906\n",
            "Step 0746\tAverage Loss: 0.54\tAccuracy: 0.896\n",
            "Step 0747\tAverage Loss: 0.75\tAccuracy: 0.897\n",
            "Step 0748\tAverage Loss: 0.47\tAccuracy: 0.905\n",
            "Step 0749\tAverage Loss: 0.28\tAccuracy: 0.911\n",
            "Step 0750\tAverage Loss: 0.24\tAccuracy: 0.910\n",
            "Step 0751\tAverage Loss: 0.43\tAccuracy: 0.907\n",
            "Step 0752\tAverage Loss: 0.33\tAccuracy: 0.909\n",
            "Step 0753\tAverage Loss: 0.23\tAccuracy: 0.907\n",
            "Step 0754\tAverage Loss: 0.30\tAccuracy: 0.908\n",
            "Step 0755\tAverage Loss: 0.30\tAccuracy: 0.910\n",
            "Step 0756\tAverage Loss: 0.22\tAccuracy: 0.913\n",
            "Step 0757\tAverage Loss: 0.41\tAccuracy: 0.911\n",
            "Step 0758\tAverage Loss: 0.32\tAccuracy: 0.911\n",
            "Step 0759\tAverage Loss: 0.51\tAccuracy: 0.908\n",
            "Step 0760\tAverage Loss: 0.41\tAccuracy: 0.910\n",
            "Step 0761\tAverage Loss: 0.24\tAccuracy: 0.909\n",
            "Step 0762\tAverage Loss: 0.27\tAccuracy: 0.912\n",
            "Step 0763\tAverage Loss: 0.24\tAccuracy: 0.908\n",
            "Step 0764\tAverage Loss: 0.24\tAccuracy: 0.904\n",
            "Step 0765\tAverage Loss: 0.42\tAccuracy: 0.908\n",
            "Step 0766\tAverage Loss: 0.39\tAccuracy: 0.909\n",
            "Step 0767\tAverage Loss: 0.34\tAccuracy: 0.912\n",
            "Step 0768\tAverage Loss: 0.27\tAccuracy: 0.912\n",
            "Step 0769\tAverage Loss: 0.28\tAccuracy: 0.910\n",
            "Step 0770\tAverage Loss: 0.34\tAccuracy: 0.910\n",
            "Step 0771\tAverage Loss: 0.35\tAccuracy: 0.910\n",
            "Step 0772\tAverage Loss: 0.39\tAccuracy: 0.912\n",
            "Step 0773\tAverage Loss: 0.10\tAccuracy: 0.910\n",
            "Step 0774\tAverage Loss: 0.45\tAccuracy: 0.907\n",
            "Step 0775\tAverage Loss: 0.48\tAccuracy: 0.905\n",
            "Step 0776\tAverage Loss: 0.33\tAccuracy: 0.908\n",
            "Step 0777\tAverage Loss: 0.35\tAccuracy: 0.907\n",
            "Step 0778\tAverage Loss: 0.41\tAccuracy: 0.911\n",
            "Step 0779\tAverage Loss: 0.23\tAccuracy: 0.910\n",
            "Step 0780\tAverage Loss: 0.28\tAccuracy: 0.911\n",
            "Step 0781\tAverage Loss: 0.24\tAccuracy: 0.911\n",
            "Step 0782\tAverage Loss: 0.23\tAccuracy: 0.908\n",
            "Step 0783\tAverage Loss: 0.21\tAccuracy: 0.906\n",
            "Step 0784\tAverage Loss: 0.35\tAccuracy: 0.897\n",
            "Step 0785\tAverage Loss: 0.38\tAccuracy: 0.903\n",
            "Step 0786\tAverage Loss: 0.23\tAccuracy: 0.908\n",
            "Step 0787\tAverage Loss: 0.28\tAccuracy: 0.912\n",
            "Step 0788\tAverage Loss: 0.30\tAccuracy: 0.912\n",
            "Step 0789\tAverage Loss: 0.24\tAccuracy: 0.910\n",
            "Step 0790\tAverage Loss: 0.32\tAccuracy: 0.909\n",
            "Step 0791\tAverage Loss: 0.27\tAccuracy: 0.912\n",
            "Step 0792\tAverage Loss: 0.35\tAccuracy: 0.909\n",
            "Step 0793\tAverage Loss: 0.25\tAccuracy: 0.911\n",
            "Step 0794\tAverage Loss: 0.23\tAccuracy: 0.909\n",
            "Step 0795\tAverage Loss: 0.37\tAccuracy: 0.902\n",
            "Step 0796\tAverage Loss: 0.16\tAccuracy: 0.907\n",
            "Step 0797\tAverage Loss: 0.19\tAccuracy: 0.909\n",
            "Step 0798\tAverage Loss: 0.38\tAccuracy: 0.904\n",
            "Step 0799\tAverage Loss: 0.30\tAccuracy: 0.903\n",
            "Step 0800\tAverage Loss: 0.41\tAccuracy: 0.908\n",
            "Step 0801\tAverage Loss: 0.38\tAccuracy: 0.910\n",
            "Step 0802\tAverage Loss: 0.30\tAccuracy: 0.908\n",
            "Step 0803\tAverage Loss: 0.24\tAccuracy: 0.910\n",
            "Step 0804\tAverage Loss: 0.16\tAccuracy: 0.910\n",
            "Step 0805\tAverage Loss: 0.35\tAccuracy: 0.912\n",
            "Step 0806\tAverage Loss: 0.34\tAccuracy: 0.912\n",
            "Step 0807\tAverage Loss: 0.47\tAccuracy: 0.900\n",
            "Step 0808\tAverage Loss: 0.43\tAccuracy: 0.897\n",
            "Step 0809\tAverage Loss: 0.73\tAccuracy: 0.900\n",
            "Step 0810\tAverage Loss: 0.43\tAccuracy: 0.905\n",
            "Step 0811\tAverage Loss: 0.35\tAccuracy: 0.908\n",
            "Step 0812\tAverage Loss: 0.19\tAccuracy: 0.912\n",
            "Step 0813\tAverage Loss: 0.32\tAccuracy: 0.909\n",
            "Step 0814\tAverage Loss: 0.18\tAccuracy: 0.909\n",
            "Step 0815\tAverage Loss: 0.32\tAccuracy: 0.908\n",
            "Step 0816\tAverage Loss: 0.33\tAccuracy: 0.908\n",
            "Step 0817\tAverage Loss: 0.20\tAccuracy: 0.909\n",
            "Step 0818\tAverage Loss: 0.16\tAccuracy: 0.912\n",
            "Step 0819\tAverage Loss: 0.35\tAccuracy: 0.911\n",
            "Step 0820\tAverage Loss: 0.14\tAccuracy: 0.911\n",
            "Step 0821\tAverage Loss: 0.33\tAccuracy: 0.910\n",
            "Step 0822\tAverage Loss: 0.52\tAccuracy: 0.909\n",
            "Step 0823\tAverage Loss: 0.15\tAccuracy: 0.911\n",
            "Step 0824\tAverage Loss: 0.38\tAccuracy: 0.910\n",
            "Step 0825\tAverage Loss: 0.70\tAccuracy: 0.905\n",
            "Step 0826\tAverage Loss: 0.31\tAccuracy: 0.901\n",
            "Step 0827\tAverage Loss: 0.30\tAccuracy: 0.905\n",
            "Step 0828\tAverage Loss: 0.19\tAccuracy: 0.902\n",
            "Step 0829\tAverage Loss: 0.17\tAccuracy: 0.904\n",
            "Step 0830\tAverage Loss: 0.44\tAccuracy: 0.910\n",
            "Step 0831\tAverage Loss: 0.30\tAccuracy: 0.910\n",
            "Step 0832\tAverage Loss: 0.24\tAccuracy: 0.913\n",
            "Step 0833\tAverage Loss: 0.25\tAccuracy: 0.912\n",
            "Step 0834\tAverage Loss: 0.33\tAccuracy: 0.909\n",
            "Step 0835\tAverage Loss: 0.27\tAccuracy: 0.913\n",
            "Step 0836\tAverage Loss: 0.26\tAccuracy: 0.904\n",
            "Step 0837\tAverage Loss: 0.37\tAccuracy: 0.914\n",
            "Step 0838\tAverage Loss: 0.35\tAccuracy: 0.912\n",
            "Step 0839\tAverage Loss: 0.39\tAccuracy: 0.909\n",
            "Step 0840\tAverage Loss: 0.34\tAccuracy: 0.911\n",
            "Step 0841\tAverage Loss: 0.26\tAccuracy: 0.911\n",
            "Step 0842\tAverage Loss: 0.41\tAccuracy: 0.907\n",
            "Step 0843\tAverage Loss: 0.23\tAccuracy: 0.911\n",
            "Step 0844\tAverage Loss: 0.29\tAccuracy: 0.912\n",
            "Step 0845\tAverage Loss: 0.35\tAccuracy: 0.907\n",
            "Step 0846\tAverage Loss: 0.40\tAccuracy: 0.907\n",
            "Step 0847\tAverage Loss: 0.53\tAccuracy: 0.899\n",
            "Step 0848\tAverage Loss: 0.31\tAccuracy: 0.909\n",
            "Step 0849\tAverage Loss: 0.37\tAccuracy: 0.912\n",
            "Step 0850\tAverage Loss: 0.21\tAccuracy: 0.911\n",
            "Step 0851\tAverage Loss: 0.25\tAccuracy: 0.909\n",
            "Step 0852\tAverage Loss: 0.24\tAccuracy: 0.910\n",
            "Step 0853\tAverage Loss: 0.32\tAccuracy: 0.908\n",
            "Step 0854\tAverage Loss: 0.20\tAccuracy: 0.909\n",
            "Step 0855\tAverage Loss: 0.26\tAccuracy: 0.910\n",
            "Step 0856\tAverage Loss: 0.23\tAccuracy: 0.907\n",
            "Step 0857\tAverage Loss: 0.25\tAccuracy: 0.910\n",
            "Step 0858\tAverage Loss: 0.29\tAccuracy: 0.911\n",
            "Step 0859\tAverage Loss: 0.24\tAccuracy: 0.910\n",
            "Step 0860\tAverage Loss: 0.23\tAccuracy: 0.906\n",
            "Step 0861\tAverage Loss: 0.19\tAccuracy: 0.908\n",
            "Step 0862\tAverage Loss: 0.24\tAccuracy: 0.908\n",
            "Step 0863\tAverage Loss: 0.52\tAccuracy: 0.910\n",
            "Step 0864\tAverage Loss: 0.30\tAccuracy: 0.908\n",
            "Step 0865\tAverage Loss: 0.38\tAccuracy: 0.909\n",
            "Step 0866\tAverage Loss: 0.50\tAccuracy: 0.910\n",
            "Step 0867\tAverage Loss: 0.53\tAccuracy: 0.903\n",
            "Step 0868\tAverage Loss: 0.46\tAccuracy: 0.910\n",
            "Step 0869\tAverage Loss: 0.20\tAccuracy: 0.911\n",
            "Step 0870\tAverage Loss: 0.19\tAccuracy: 0.908\n",
            "Step 0871\tAverage Loss: 0.55\tAccuracy: 0.906\n",
            "Step 0872\tAverage Loss: 0.39\tAccuracy: 0.897\n",
            "Step 0873\tAverage Loss: 0.23\tAccuracy: 0.904\n",
            "Step 0874\tAverage Loss: 0.30\tAccuracy: 0.904\n",
            "Step 0875\tAverage Loss: 0.32\tAccuracy: 0.905\n",
            "Step 0876\tAverage Loss: 0.35\tAccuracy: 0.909\n",
            "Step 0877\tAverage Loss: 0.38\tAccuracy: 0.910\n",
            "Step 0878\tAverage Loss: 0.29\tAccuracy: 0.909\n",
            "Step 0879\tAverage Loss: 0.20\tAccuracy: 0.909\n",
            "Step 0880\tAverage Loss: 0.15\tAccuracy: 0.910\n",
            "Step 0881\tAverage Loss: 0.37\tAccuracy: 0.908\n",
            "Step 0882\tAverage Loss: 0.19\tAccuracy: 0.903\n",
            "Step 0883\tAverage Loss: 0.51\tAccuracy: 0.910\n",
            "Step 0884\tAverage Loss: 0.27\tAccuracy: 0.909\n",
            "Step 0885\tAverage Loss: 0.27\tAccuracy: 0.909\n",
            "Step 0886\tAverage Loss: 0.66\tAccuracy: 0.909\n",
            "Step 0887\tAverage Loss: 0.30\tAccuracy: 0.905\n",
            "Step 0888\tAverage Loss: 0.19\tAccuracy: 0.910\n",
            "Step 0889\tAverage Loss: 0.24\tAccuracy: 0.912\n",
            "Step 0890\tAverage Loss: 0.27\tAccuracy: 0.912\n",
            "Step 0891\tAverage Loss: 0.37\tAccuracy: 0.910\n",
            "Step 0892\tAverage Loss: 0.38\tAccuracy: 0.909\n",
            "Step 0893\tAverage Loss: 0.30\tAccuracy: 0.906\n",
            "Step 0894\tAverage Loss: 0.26\tAccuracy: 0.908\n",
            "Step 0895\tAverage Loss: 0.29\tAccuracy: 0.906\n",
            "Step 0896\tAverage Loss: 0.24\tAccuracy: 0.906\n",
            "Step 0897\tAverage Loss: 0.41\tAccuracy: 0.907\n",
            "Step 0898\tAverage Loss: 0.46\tAccuracy: 0.909\n",
            "Step 0899\tAverage Loss: 0.55\tAccuracy: 0.906\n",
            "Step 0900\tAverage Loss: 0.32\tAccuracy: 0.907\n",
            "Step 0901\tAverage Loss: 0.51\tAccuracy: 0.906\n",
            "Step 0902\tAverage Loss: 0.29\tAccuracy: 0.906\n",
            "Step 0903\tAverage Loss: 0.25\tAccuracy: 0.910\n",
            "Step 0904\tAverage Loss: 0.31\tAccuracy: 0.912\n",
            "Step 0905\tAverage Loss: 0.31\tAccuracy: 0.911\n",
            "Step 0906\tAverage Loss: 0.49\tAccuracy: 0.912\n",
            "Step 0907\tAverage Loss: 0.27\tAccuracy: 0.910\n",
            "Step 0908\tAverage Loss: 0.45\tAccuracy: 0.906\n",
            "Step 0909\tAverage Loss: 0.30\tAccuracy: 0.904\n",
            "Step 0910\tAverage Loss: 0.35\tAccuracy: 0.911\n",
            "Step 0911\tAverage Loss: 0.69\tAccuracy: 0.911\n",
            "Step 0912\tAverage Loss: 0.38\tAccuracy: 0.909\n",
            "Step 0913\tAverage Loss: 0.65\tAccuracy: 0.910\n",
            "Step 0914\tAverage Loss: 0.35\tAccuracy: 0.911\n",
            "Step 0915\tAverage Loss: 0.25\tAccuracy: 0.907\n",
            "Step 0916\tAverage Loss: 0.39\tAccuracy: 0.911\n",
            "Step 0917\tAverage Loss: 0.58\tAccuracy: 0.908\n",
            "Step 0918\tAverage Loss: 0.37\tAccuracy: 0.908\n",
            "Step 0919\tAverage Loss: 0.27\tAccuracy: 0.908\n",
            "Step 0920\tAverage Loss: 0.35\tAccuracy: 0.909\n",
            "Step 0921\tAverage Loss: 0.42\tAccuracy: 0.909\n",
            "Step 0922\tAverage Loss: 0.45\tAccuracy: 0.911\n",
            "Step 0923\tAverage Loss: 0.44\tAccuracy: 0.889\n",
            "Step 0924\tAverage Loss: 0.46\tAccuracy: 0.899\n",
            "Step 0925\tAverage Loss: 0.26\tAccuracy: 0.904\n",
            "Step 0926\tAverage Loss: 0.35\tAccuracy: 0.908\n",
            "Step 0927\tAverage Loss: 0.43\tAccuracy: 0.910\n",
            "Step 0928\tAverage Loss: 0.30\tAccuracy: 0.907\n",
            "Step 0929\tAverage Loss: 0.32\tAccuracy: 0.910\n",
            "Step 0930\tAverage Loss: 0.27\tAccuracy: 0.909\n",
            "Step 0931\tAverage Loss: 0.19\tAccuracy: 0.906\n",
            "Step 0932\tAverage Loss: 0.37\tAccuracy: 0.908\n",
            "Step 0933\tAverage Loss: 0.40\tAccuracy: 0.908\n",
            "Step 0934\tAverage Loss: 0.32\tAccuracy: 0.908\n",
            "Step 0935\tAverage Loss: 0.32\tAccuracy: 0.910\n",
            "Step 0936\tAverage Loss: 0.18\tAccuracy: 0.913\n",
            "Step 0937\tAverage Loss: 0.25\tAccuracy: 0.907\n",
            "Step 0938\tAverage Loss: 0.11\tAccuracy: 0.909\n",
            "Step 0939\tAverage Loss: 0.16\tAccuracy: 0.911\n",
            "Step 0940\tAverage Loss: 0.27\tAccuracy: 0.910\n",
            "Step 0941\tAverage Loss: 0.17\tAccuracy: 0.908\n",
            "Step 0942\tAverage Loss: 0.18\tAccuracy: 0.910\n",
            "Step 0943\tAverage Loss: 0.18\tAccuracy: 0.910\n",
            "Step 0944\tAverage Loss: 0.45\tAccuracy: 0.905\n",
            "Step 0945\tAverage Loss: 0.48\tAccuracy: 0.900\n",
            "Step 0946\tAverage Loss: 0.44\tAccuracy: 0.910\n",
            "Step 0947\tAverage Loss: 0.28\tAccuracy: 0.910\n",
            "Step 0948\tAverage Loss: 0.54\tAccuracy: 0.910\n",
            "Step 0949\tAverage Loss: 0.29\tAccuracy: 0.912\n",
            "Step 0950\tAverage Loss: 0.26\tAccuracy: 0.911\n",
            "Step 0951\tAverage Loss: 0.28\tAccuracy: 0.909\n",
            "Step 0952\tAverage Loss: 0.25\tAccuracy: 0.911\n",
            "Step 0953\tAverage Loss: 0.23\tAccuracy: 0.910\n",
            "Step 0954\tAverage Loss: 0.44\tAccuracy: 0.911\n",
            "Step 0955\tAverage Loss: 0.17\tAccuracy: 0.908\n",
            "Step 0956\tAverage Loss: 0.34\tAccuracy: 0.903\n",
            "Step 0957\tAverage Loss: 0.19\tAccuracy: 0.912\n",
            "Step 0958\tAverage Loss: 0.20\tAccuracy: 0.911\n",
            "Step 0959\tAverage Loss: 0.30\tAccuracy: 0.912\n",
            "Step 0960\tAverage Loss: 0.38\tAccuracy: 0.908\n",
            "Step 0961\tAverage Loss: 0.30\tAccuracy: 0.909\n",
            "Step 0962\tAverage Loss: 0.24\tAccuracy: 0.910\n",
            "Step 0963\tAverage Loss: 0.22\tAccuracy: 0.910\n",
            "Step 0964\tAverage Loss: 0.42\tAccuracy: 0.906\n",
            "Step 0965\tAverage Loss: 0.17\tAccuracy: 0.903\n",
            "Step 0966\tAverage Loss: 0.11\tAccuracy: 0.906\n",
            "Step 0967\tAverage Loss: 0.35\tAccuracy: 0.906\n",
            "Step 0968\tAverage Loss: 0.32\tAccuracy: 0.905\n",
            "Step 0969\tAverage Loss: 0.21\tAccuracy: 0.903\n",
            "Step 0970\tAverage Loss: 0.41\tAccuracy: 0.903\n",
            "Step 0971\tAverage Loss: 0.43\tAccuracy: 0.905\n",
            "Step 0972\tAverage Loss: 0.42\tAccuracy: 0.904\n",
            "Step 0973\tAverage Loss: 0.84\tAccuracy: 0.902\n",
            "Step 0974\tAverage Loss: 0.82\tAccuracy: 0.907\n",
            "Step 0975\tAverage Loss: 0.43\tAccuracy: 0.901\n",
            "Step 0976\tAverage Loss: 0.30\tAccuracy: 0.908\n",
            "Step 0977\tAverage Loss: 0.35\tAccuracy: 0.909\n",
            "Step 0978\tAverage Loss: 0.33\tAccuracy: 0.912\n",
            "Step 0979\tAverage Loss: 0.40\tAccuracy: 0.911\n",
            "Step 0980\tAverage Loss: 0.30\tAccuracy: 0.910\n",
            "Step 0981\tAverage Loss: 0.16\tAccuracy: 0.907\n",
            "Step 0982\tAverage Loss: 0.37\tAccuracy: 0.910\n",
            "Step 0983\tAverage Loss: 0.37\tAccuracy: 0.903\n",
            "Step 0984\tAverage Loss: 0.20\tAccuracy: 0.908\n",
            "Step 0985\tAverage Loss: 0.52\tAccuracy: 0.908\n",
            "Step 0986\tAverage Loss: 0.41\tAccuracy: 0.907\n",
            "Step 0987\tAverage Loss: 0.27\tAccuracy: 0.912\n",
            "Step 0988\tAverage Loss: 0.12\tAccuracy: 0.909\n",
            "Step 0989\tAverage Loss: 0.18\tAccuracy: 0.910\n",
            "Step 0990\tAverage Loss: 0.21\tAccuracy: 0.913\n",
            "Step 0991\tAverage Loss: 0.31\tAccuracy: 0.913\n",
            "Step 0992\tAverage Loss: 0.26\tAccuracy: 0.910\n",
            "Step 0993\tAverage Loss: 0.63\tAccuracy: 0.906\n",
            "Step 0994\tAverage Loss: 0.64\tAccuracy: 0.895\n",
            "Step 0995\tAverage Loss: 0.25\tAccuracy: 0.908\n",
            "Step 0996\tAverage Loss: 0.38\tAccuracy: 0.908\n",
            "Step 0997\tAverage Loss: 0.30\tAccuracy: 0.911\n",
            "Step 0998\tAverage Loss: 0.26\tAccuracy: 0.905\n",
            "Step 0999\tAverage Loss: 0.38\tAccuracy: 0.908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc mnist.c neural_network.c mnist_file.c -o mnist -lm\n"
      ],
      "metadata": {
        "id": "rOlU4yYwaNBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./mnist\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27w5Q0TWaOll",
        "outputId": "95bfd0d9-b7d0-4de8-ae3a-2de5aa6ba555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0000\tAverage Loss: 4.36\tAccuracy: 0.152\t\n",
            "Step 0001\tAverage Loss: 3.42\tAccuracy: 0.188\t\n",
            "Step 0002\tAverage Loss: 2.97\tAccuracy: 0.298\t\n",
            "Step 0003\tAverage Loss: 2.53\tAccuracy: 0.319\t\n",
            "Step 0004\tAverage Loss: 2.19\tAccuracy: 0.412\t\n",
            "Step 0005\tAverage Loss: 2.08\tAccuracy: 0.437\t\n",
            "Step 0006\tAverage Loss: 1.73\tAccuracy: 0.468\t\n",
            "Step 0007\tAverage Loss: 1.51\tAccuracy: 0.447\t\n",
            "Step 0008\tAverage Loss: 1.57\tAccuracy: 0.496\t\n",
            "Step 0009\tAverage Loss: 1.45\tAccuracy: 0.516\t\n",
            "Step 0010\tAverage Loss: 1.78\tAccuracy: 0.559\t\n",
            "Step 0011\tAverage Loss: 1.68\tAccuracy: 0.559\t\n",
            "Step 0012\tAverage Loss: 1.21\tAccuracy: 0.548\t\n",
            "Step 0013\tAverage Loss: 1.89\tAccuracy: 0.564\t\n",
            "Step 0014\tAverage Loss: 1.43\tAccuracy: 0.625\t\n",
            "Step 0015\tAverage Loss: 1.11\tAccuracy: 0.656\t\n",
            "Step 0016\tAverage Loss: 0.90\tAccuracy: 0.655\t\n",
            "Step 0017\tAverage Loss: 0.62\tAccuracy: 0.681\t\n",
            "Step 0018\tAverage Loss: 0.87\tAccuracy: 0.677\t\n",
            "Step 0019\tAverage Loss: 0.95\tAccuracy: 0.696\t\n",
            "Step 0020\tAverage Loss: 0.90\tAccuracy: 0.703\t\n",
            "Step 0021\tAverage Loss: 0.68\tAccuracy: 0.716\t\n",
            "Step 0022\tAverage Loss: 0.82\tAccuracy: 0.708\t\n",
            "Step 0023\tAverage Loss: 0.75\tAccuracy: 0.713\t\n",
            "Step 0024\tAverage Loss: 0.87\tAccuracy: 0.676\t\n",
            "Step 0025\tAverage Loss: 0.79\tAccuracy: 0.740\t\n",
            "Step 0026\tAverage Loss: 0.81\tAccuracy: 0.747\t\n",
            "Step 0027\tAverage Loss: 0.86\tAccuracy: 0.729\t\n",
            "Step 0028\tAverage Loss: 0.62\tAccuracy: 0.755\t\n",
            "Step 0029\tAverage Loss: 0.59\tAccuracy: 0.756\t\n",
            "Step 0030\tAverage Loss: 0.94\tAccuracy: 0.740\t\n",
            "Step 0031\tAverage Loss: 0.63\tAccuracy: 0.775\t\n",
            "Step 0032\tAverage Loss: 0.72\tAccuracy: 0.779\t\n",
            "Step 0033\tAverage Loss: 0.66\tAccuracy: 0.764\t\n",
            "Step 0034\tAverage Loss: 0.71\tAccuracy: 0.761\t\n",
            "Step 0035\tAverage Loss: 0.83\tAccuracy: 0.779\t\n",
            "Step 0036\tAverage Loss: 0.64\tAccuracy: 0.785\t\n",
            "Step 0037\tAverage Loss: 0.79\tAccuracy: 0.775\t\n",
            "Step 0038\tAverage Loss: 0.58\tAccuracy: 0.794\t\n",
            "Step 0039\tAverage Loss: 0.57\tAccuracy: 0.796\t\n",
            "Step 0040\tAverage Loss: 0.67\tAccuracy: 0.775\t\n",
            "Step 0041\tAverage Loss: 0.74\tAccuracy: 0.804\t\n",
            "Step 0042\tAverage Loss: 0.60\tAccuracy: 0.790\t\n",
            "Step 0043\tAverage Loss: 0.59\tAccuracy: 0.798\t\n",
            "Step 0044\tAverage Loss: 0.59\tAccuracy: 0.805\t\n",
            "Step 0045\tAverage Loss: 0.45\tAccuracy: 0.806\t\n",
            "Step 0046\tAverage Loss: 0.74\tAccuracy: 0.787\t\n",
            "Step 0047\tAverage Loss: 0.74\tAccuracy: 0.799\t\n",
            "Step 0048\tAverage Loss: 0.48\tAccuracy: 0.785\t\n",
            "Step 0049\tAverage Loss: 0.69\tAccuracy: 0.815\t\n",
            "Step 0050\tAverage Loss: 0.56\tAccuracy: 0.814\t\n",
            "Step 0051\tAverage Loss: 0.90\tAccuracy: 0.815\t\n",
            "Step 0052\tAverage Loss: 0.40\tAccuracy: 0.815\t\n",
            "Step 0053\tAverage Loss: 0.70\tAccuracy: 0.819\t\n",
            "Step 0054\tAverage Loss: 0.36\tAccuracy: 0.819\t\n",
            "Step 0055\tAverage Loss: 0.55\tAccuracy: 0.796\t\n",
            "Step 0056\tAverage Loss: 0.60\tAccuracy: 0.820\t\n",
            "Step 0057\tAverage Loss: 0.60\tAccuracy: 0.812\t\n",
            "Step 0058\tAverage Loss: 0.53\tAccuracy: 0.817\t\n",
            "Step 0059\tAverage Loss: 0.46\tAccuracy: 0.825\t\n",
            "Step 0060\tAverage Loss: 0.34\tAccuracy: 0.826\t\n",
            "Step 0061\tAverage Loss: 0.55\tAccuracy: 0.824\t\n",
            "Step 0062\tAverage Loss: 0.53\tAccuracy: 0.821\t\n",
            "Step 0063\tAverage Loss: 0.40\tAccuracy: 0.821\t\n",
            "Step 0064\tAverage Loss: 0.54\tAccuracy: 0.828\t\n",
            "Step 0065\tAverage Loss: 0.33\tAccuracy: 0.831\t\n",
            "Step 0066\tAverage Loss: 0.53\tAccuracy: 0.830\t\n",
            "Step 0067\tAverage Loss: 0.46\tAccuracy: 0.823\t\n",
            "Step 0068\tAverage Loss: 0.67\tAccuracy: 0.833\t\n",
            "Step 0069\tAverage Loss: 0.59\tAccuracy: 0.818\t\n",
            "Step 0070\tAverage Loss: 0.62\tAccuracy: 0.836\t\n",
            "Step 0071\tAverage Loss: 0.53\tAccuracy: 0.837\t\n",
            "Step 0072\tAverage Loss: 0.77\tAccuracy: 0.834\t\n",
            "Step 0073\tAverage Loss: 0.63\tAccuracy: 0.837\t\n",
            "Step 0074\tAverage Loss: 0.47\tAccuracy: 0.835\t\n",
            "Step 0075\tAverage Loss: 0.45\tAccuracy: 0.837\t\n",
            "Step 0076\tAverage Loss: 0.65\tAccuracy: 0.834\t\n",
            "Step 0077\tAverage Loss: 0.53\tAccuracy: 0.829\t\n",
            "Step 0078\tAverage Loss: 0.74\tAccuracy: 0.838\t\n",
            "Step 0079\tAverage Loss: 0.65\tAccuracy: 0.837\t\n",
            "Step 0080\tAverage Loss: 0.54\tAccuracy: 0.841\t\n",
            "Step 0081\tAverage Loss: 0.57\tAccuracy: 0.831\t\n",
            "Step 0082\tAverage Loss: 0.82\tAccuracy: 0.837\t\n",
            "Step 0083\tAverage Loss: 0.49\tAccuracy: 0.845\t\n",
            "Step 0084\tAverage Loss: 0.72\tAccuracy: 0.836\t\n",
            "Step 0085\tAverage Loss: 0.36\tAccuracy: 0.838\t\n",
            "Step 0086\tAverage Loss: 0.67\tAccuracy: 0.830\t\n",
            "Step 0087\tAverage Loss: 1.00\tAccuracy: 0.840\t\n",
            "Step 0088\tAverage Loss: 0.73\tAccuracy: 0.822\t\n",
            "Step 0089\tAverage Loss: 0.44\tAccuracy: 0.839\t\n",
            "Step 0090\tAverage Loss: 0.36\tAccuracy: 0.841\t\n",
            "Step 0091\tAverage Loss: 0.42\tAccuracy: 0.845\t\n",
            "Step 0092\tAverage Loss: 0.58\tAccuracy: 0.845\t\n",
            "Step 0093\tAverage Loss: 0.59\tAccuracy: 0.834\t\n",
            "Step 0094\tAverage Loss: 0.59\tAccuracy: 0.842\t\n",
            "Step 0095\tAverage Loss: 0.62\tAccuracy: 0.837\t\n",
            "Step 0096\tAverage Loss: 0.44\tAccuracy: 0.844\t\n",
            "Step 0097\tAverage Loss: 0.45\tAccuracy: 0.847\t\n",
            "Step 0098\tAverage Loss: 0.30\tAccuracy: 0.845\t\n",
            "Step 0099\tAverage Loss: 0.26\tAccuracy: 0.845\t\n",
            "Step 0100\tAverage Loss: 0.43\tAccuracy: 0.850\t\n",
            "Step 0101\tAverage Loss: 0.34\tAccuracy: 0.850\t\n",
            "Step 0102\tAverage Loss: 0.69\tAccuracy: 0.808\t\n",
            "Step 0103\tAverage Loss: 0.29\tAccuracy: 0.830\t\n",
            "Step 0104\tAverage Loss: 0.38\tAccuracy: 0.846\t\n",
            "Step 0105\tAverage Loss: 0.28\tAccuracy: 0.852\t\n",
            "Step 0106\tAverage Loss: 0.39\tAccuracy: 0.847\t\n",
            "Step 0107\tAverage Loss: 0.61\tAccuracy: 0.852\t\n",
            "Step 0108\tAverage Loss: 0.44\tAccuracy: 0.857\t\n",
            "Step 0109\tAverage Loss: 0.37\tAccuracy: 0.858\t\n",
            "Step 0110\tAverage Loss: 0.34\tAccuracy: 0.856\t\n",
            "Step 0111\tAverage Loss: 0.34\tAccuracy: 0.859\t\n",
            "Step 0112\tAverage Loss: 0.57\tAccuracy: 0.854\t\n",
            "Step 0113\tAverage Loss: 0.32\tAccuracy: 0.854\t\n",
            "Step 0114\tAverage Loss: 0.35\tAccuracy: 0.857\t\n",
            "Step 0115\tAverage Loss: 0.69\tAccuracy: 0.855\t\n",
            "Step 0116\tAverage Loss: 0.52\tAccuracy: 0.852\t\n",
            "Step 0117\tAverage Loss: 0.63\tAccuracy: 0.846\t\n",
            "Step 0118\tAverage Loss: 0.45\tAccuracy: 0.840\t\n",
            "Step 0119\tAverage Loss: 0.41\tAccuracy: 0.840\t\n",
            "Step 0120\tAverage Loss: 0.51\tAccuracy: 0.846\t\n",
            "Step 0121\tAverage Loss: 0.38\tAccuracy: 0.832\t\n",
            "Step 0122\tAverage Loss: 0.57\tAccuracy: 0.852\t\n",
            "Step 0123\tAverage Loss: 0.54\tAccuracy: 0.854\t\n",
            "Step 0124\tAverage Loss: 0.53\tAccuracy: 0.854\t\n",
            "Step 0125\tAverage Loss: 0.77\tAccuracy: 0.847\t\n",
            "Step 0126\tAverage Loss: 0.85\tAccuracy: 0.848\t\n",
            "Step 0127\tAverage Loss: 0.47\tAccuracy: 0.860\t\n",
            "Step 0128\tAverage Loss: 0.31\tAccuracy: 0.861\t\n",
            "Step 0129\tAverage Loss: 0.66\tAccuracy: 0.861\t\n",
            "Step 0130\tAverage Loss: 0.82\tAccuracy: 0.855\t\n",
            "Step 0131\tAverage Loss: 0.63\tAccuracy: 0.857\t\n",
            "Step 0132\tAverage Loss: 0.41\tAccuracy: 0.851\t\n",
            "Step 0133\tAverage Loss: 0.51\tAccuracy: 0.862\t\n",
            "Step 0134\tAverage Loss: 0.30\tAccuracy: 0.862\t\n",
            "Step 0135\tAverage Loss: 0.29\tAccuracy: 0.861\t\n",
            "Step 0136\tAverage Loss: 0.55\tAccuracy: 0.860\t\n",
            "Step 0137\tAverage Loss: 0.56\tAccuracy: 0.864\t\n",
            "Step 0138\tAverage Loss: 0.43\tAccuracy: 0.862\t\n",
            "Step 0139\tAverage Loss: 0.77\tAccuracy: 0.864\t\n",
            "Step 0140\tAverage Loss: 0.57\tAccuracy: 0.868\t\n",
            "Step 0141\tAverage Loss: 0.53\tAccuracy: 0.858\t\n",
            "Step 0142\tAverage Loss: 0.60\tAccuracy: 0.866\t\n",
            "Step 0143\tAverage Loss: 0.65\tAccuracy: 0.863\t\n",
            "Step 0144\tAverage Loss: 0.41\tAccuracy: 0.870\t\n",
            "Step 0145\tAverage Loss: 0.59\tAccuracy: 0.864\t\n",
            "Step 0146\tAverage Loss: 0.76\tAccuracy: 0.857\t\n",
            "Step 0147\tAverage Loss: 0.81\tAccuracy: 0.855\t\n",
            "Step 0148\tAverage Loss: 0.64\tAccuracy: 0.866\t\n",
            "Step 0149\tAverage Loss: 0.39\tAccuracy: 0.870\t\n",
            "Step 0150\tAverage Loss: 0.29\tAccuracy: 0.873\t\n",
            "Step 0151\tAverage Loss: 0.50\tAccuracy: 0.871\t\n",
            "Step 0152\tAverage Loss: 0.40\tAccuracy: 0.872\t\n",
            "Step 0153\tAverage Loss: 0.34\tAccuracy: 0.869\t\n",
            "Step 0154\tAverage Loss: 0.40\tAccuracy: 0.871\t\n",
            "Step 0155\tAverage Loss: 0.47\tAccuracy: 0.873\t\n",
            "Step 0156\tAverage Loss: 0.35\tAccuracy: 0.872\t\n",
            "Step 0157\tAverage Loss: 0.58\tAccuracy: 0.877\t\n",
            "Step 0158\tAverage Loss: 0.56\tAccuracy: 0.869\t\n",
            "Step 0159\tAverage Loss: 0.63\tAccuracy: 0.873\t\n",
            "Step 0160\tAverage Loss: 0.53\tAccuracy: 0.872\t\n",
            "Step 0161\tAverage Loss: 0.32\tAccuracy: 0.872\t\n",
            "Step 0162\tAverage Loss: 0.44\tAccuracy: 0.873\t\n",
            "Step 0163\tAverage Loss: 0.34\tAccuracy: 0.868\t\n",
            "Step 0164\tAverage Loss: 0.32\tAccuracy: 0.865\t\n",
            "Step 0165\tAverage Loss: 0.51\tAccuracy: 0.875\t\n",
            "Step 0166\tAverage Loss: 0.52\tAccuracy: 0.876\t\n",
            "Step 0167\tAverage Loss: 0.43\tAccuracy: 0.877\t\n",
            "Step 0168\tAverage Loss: 0.44\tAccuracy: 0.877\t\n",
            "Step 0169\tAverage Loss: 0.48\tAccuracy: 0.875\t\n",
            "Step 0170\tAverage Loss: 0.44\tAccuracy: 0.877\t\n",
            "Step 0171\tAverage Loss: 0.48\tAccuracy: 0.873\t\n",
            "Step 0172\tAverage Loss: 0.56\tAccuracy: 0.879\t\n",
            "Step 0173\tAverage Loss: 0.21\tAccuracy: 0.873\t\n",
            "Step 0174\tAverage Loss: 0.60\tAccuracy: 0.871\t\n",
            "Step 0175\tAverage Loss: 0.70\tAccuracy: 0.871\t\n",
            "Step 0176\tAverage Loss: 0.51\tAccuracy: 0.872\t\n",
            "Step 0177\tAverage Loss: 0.49\tAccuracy: 0.871\t\n",
            "Step 0178\tAverage Loss: 0.56\tAccuracy: 0.881\t\n",
            "Step 0179\tAverage Loss: 0.32\tAccuracy: 0.878\t\n",
            "Step 0180\tAverage Loss: 0.39\tAccuracy: 0.876\t\n",
            "Step 0181\tAverage Loss: 0.36\tAccuracy: 0.881\t\n",
            "Step 0182\tAverage Loss: 0.34\tAccuracy: 0.873\t\n",
            "Step 0183\tAverage Loss: 0.28\tAccuracy: 0.879\t\n",
            "Step 0184\tAverage Loss: 0.43\tAccuracy: 0.866\t\n",
            "Step 0185\tAverage Loss: 0.40\tAccuracy: 0.877\t\n",
            "Step 0186\tAverage Loss: 0.37\tAccuracy: 0.879\t\n",
            "Step 0187\tAverage Loss: 0.31\tAccuracy: 0.880\t\n",
            "Step 0188\tAverage Loss: 0.38\tAccuracy: 0.882\t\n",
            "Step 0189\tAverage Loss: 0.35\tAccuracy: 0.882\t\n",
            "Step 0190\tAverage Loss: 0.44\tAccuracy: 0.879\t\n",
            "Step 0191\tAverage Loss: 0.38\tAccuracy: 0.882\t\n",
            "Step 0192\tAverage Loss: 0.49\tAccuracy: 0.881\t\n",
            "Step 0193\tAverage Loss: 0.43\tAccuracy: 0.881\t\n",
            "Step 0194\tAverage Loss: 0.31\tAccuracy: 0.882\t\n",
            "Step 0195\tAverage Loss: 0.45\tAccuracy: 0.868\t\n",
            "Step 0196\tAverage Loss: 0.24\tAccuracy: 0.881\t\n",
            "Step 0197\tAverage Loss: 0.20\tAccuracy: 0.880\t\n",
            "Step 0198\tAverage Loss: 0.49\tAccuracy: 0.875\t\n",
            "Step 0199\tAverage Loss: 0.45\tAccuracy: 0.867\t\n",
            "Step 0200\tAverage Loss: 0.60\tAccuracy: 0.873\t\n",
            "Step 0201\tAverage Loss: 0.53\tAccuracy: 0.878\t\n",
            "Step 0202\tAverage Loss: 0.43\tAccuracy: 0.878\t\n",
            "Step 0203\tAverage Loss: 0.34\tAccuracy: 0.884\t\n",
            "Step 0204\tAverage Loss: 0.20\tAccuracy: 0.884\t\n",
            "Step 0205\tAverage Loss: 0.45\tAccuracy: 0.884\t\n",
            "Step 0206\tAverage Loss: 0.38\tAccuracy: 0.880\t\n",
            "Step 0207\tAverage Loss: 0.51\tAccuracy: 0.868\t\n",
            "Step 0208\tAverage Loss: 0.51\tAccuracy: 0.866\t\n",
            "Step 0209\tAverage Loss: 0.80\tAccuracy: 0.871\t\n",
            "Step 0210\tAverage Loss: 0.49\tAccuracy: 0.881\t\n",
            "Step 0211\tAverage Loss: 0.40\tAccuracy: 0.880\t\n",
            "Step 0212\tAverage Loss: 0.23\tAccuracy: 0.884\t\n",
            "Step 0213\tAverage Loss: 0.42\tAccuracy: 0.879\t\n",
            "Step 0214\tAverage Loss: 0.28\tAccuracy: 0.881\t\n",
            "Step 0215\tAverage Loss: 0.41\tAccuracy: 0.880\t\n",
            "Step 0216\tAverage Loss: 0.39\tAccuracy: 0.884\t\n",
            "Step 0217\tAverage Loss: 0.26\tAccuracy: 0.886\t\n",
            "Step 0218\tAverage Loss: 0.25\tAccuracy: 0.887\t\n",
            "Step 0219\tAverage Loss: 0.42\tAccuracy: 0.885\t\n",
            "Step 0220\tAverage Loss: 0.24\tAccuracy: 0.884\t\n",
            "Step 0221\tAverage Loss: 0.49\tAccuracy: 0.881\t\n",
            "Step 0222\tAverage Loss: 0.56\tAccuracy: 0.883\t\n",
            "Step 0223\tAverage Loss: 0.24\tAccuracy: 0.882\t\n",
            "Step 0224\tAverage Loss: 0.53\tAccuracy: 0.885\t\n",
            "Step 0225\tAverage Loss: 0.96\tAccuracy: 0.877\t\n",
            "Step 0226\tAverage Loss: 0.38\tAccuracy: 0.868\t\n",
            "Step 0227\tAverage Loss: 0.42\tAccuracy: 0.875\t\n",
            "Step 0228\tAverage Loss: 0.25\tAccuracy: 0.877\t\n",
            "Step 0229\tAverage Loss: 0.26\tAccuracy: 0.874\t\n",
            "Step 0230\tAverage Loss: 0.47\tAccuracy: 0.888\t\n",
            "Step 0231\tAverage Loss: 0.35\tAccuracy: 0.888\t\n",
            "Step 0232\tAverage Loss: 0.35\tAccuracy: 0.887\t\n",
            "Step 0233\tAverage Loss: 0.33\tAccuracy: 0.886\t\n",
            "Step 0234\tAverage Loss: 0.39\tAccuracy: 0.883\t\n",
            "Step 0235\tAverage Loss: 0.34\tAccuracy: 0.887\t\n",
            "Step 0236\tAverage Loss: 0.35\tAccuracy: 0.875\t\n",
            "Step 0237\tAverage Loss: 0.45\tAccuracy: 0.889\t\n",
            "Step 0238\tAverage Loss: 0.48\tAccuracy: 0.886\t\n",
            "Step 0239\tAverage Loss: 0.42\tAccuracy: 0.883\t\n",
            "Step 0240\tAverage Loss: 0.42\tAccuracy: 0.886\t\n",
            "Step 0241\tAverage Loss: 0.33\tAccuracy: 0.886\t\n",
            "Step 0242\tAverage Loss: 0.55\tAccuracy: 0.883\t\n",
            "Step 0243\tAverage Loss: 0.33\tAccuracy: 0.887\t\n",
            "Step 0244\tAverage Loss: 0.39\tAccuracy: 0.890\t\n",
            "Step 0245\tAverage Loss: 0.40\tAccuracy: 0.883\t\n",
            "Step 0246\tAverage Loss: 0.48\tAccuracy: 0.885\t\n",
            "Step 0247\tAverage Loss: 0.62\tAccuracy: 0.876\t\n",
            "Step 0248\tAverage Loss: 0.39\tAccuracy: 0.891\t\n",
            "Step 0249\tAverage Loss: 0.46\tAccuracy: 0.890\t\n",
            "Step 0250\tAverage Loss: 0.28\tAccuracy: 0.888\t\n",
            "Step 0251\tAverage Loss: 0.34\tAccuracy: 0.885\t\n",
            "Step 0252\tAverage Loss: 0.33\tAccuracy: 0.888\t\n",
            "Step 0253\tAverage Loss: 0.36\tAccuracy: 0.890\t\n",
            "Step 0254\tAverage Loss: 0.28\tAccuracy: 0.885\t\n",
            "Step 0255\tAverage Loss: 0.30\tAccuracy: 0.887\t\n",
            "Step 0256\tAverage Loss: 0.30\tAccuracy: 0.885\t\n",
            "Step 0257\tAverage Loss: 0.28\tAccuracy: 0.891\t\n",
            "Step 0258\tAverage Loss: 0.36\tAccuracy: 0.891\t\n",
            "Step 0259\tAverage Loss: 0.32\tAccuracy: 0.891\t\n",
            "Step 0260\tAverage Loss: 0.26\tAccuracy: 0.887\t\n",
            "Step 0261\tAverage Loss: 0.24\tAccuracy: 0.890\t\n",
            "Step 0262\tAverage Loss: 0.30\tAccuracy: 0.891\t\n",
            "Step 0263\tAverage Loss: 0.55\tAccuracy: 0.891\t\n",
            "Step 0264\tAverage Loss: 0.40\tAccuracy: 0.891\t\n",
            "Step 0265\tAverage Loss: 0.43\tAccuracy: 0.891\t\n",
            "Step 0266\tAverage Loss: 0.57\tAccuracy: 0.891\t\n",
            "Step 0267\tAverage Loss: 0.53\tAccuracy: 0.882\t\n",
            "Step 0268\tAverage Loss: 0.48\tAccuracy: 0.889\t\n",
            "Step 0269\tAverage Loss: 0.29\tAccuracy: 0.889\t\n",
            "Step 0270\tAverage Loss: 0.25\tAccuracy: 0.884\t\n",
            "Step 0271\tAverage Loss: 0.57\tAccuracy: 0.883\t\n",
            "Step 0272\tAverage Loss: 0.47\tAccuracy: 0.871\t\n",
            "Step 0273\tAverage Loss: 0.27\tAccuracy: 0.881\t\n",
            "Step 0274\tAverage Loss: 0.40\tAccuracy: 0.883\t\n",
            "Step 0275\tAverage Loss: 0.36\tAccuracy: 0.887\t\n",
            "Step 0276\tAverage Loss: 0.44\tAccuracy: 0.891\t\n",
            "Step 0277\tAverage Loss: 0.47\tAccuracy: 0.890\t\n",
            "Step 0278\tAverage Loss: 0.36\tAccuracy: 0.887\t\n",
            "Step 0279\tAverage Loss: 0.27\tAccuracy: 0.888\t\n",
            "Step 0280\tAverage Loss: 0.23\tAccuracy: 0.890\t\n",
            "Step 0281\tAverage Loss: 0.49\tAccuracy: 0.886\t\n",
            "Step 0282\tAverage Loss: 0.24\tAccuracy: 0.878\t\n",
            "Step 0283\tAverage Loss: 0.60\tAccuracy: 0.890\t\n",
            "Step 0284\tAverage Loss: 0.31\tAccuracy: 0.890\t\n",
            "Step 0285\tAverage Loss: 0.31\tAccuracy: 0.890\t\n",
            "Step 0286\tAverage Loss: 0.81\tAccuracy: 0.888\t\n",
            "Step 0287\tAverage Loss: 0.38\tAccuracy: 0.887\t\n",
            "Step 0288\tAverage Loss: 0.23\tAccuracy: 0.891\t\n",
            "Step 0289\tAverage Loss: 0.30\tAccuracy: 0.892\t\n",
            "Step 0290\tAverage Loss: 0.34\tAccuracy: 0.894\t\n",
            "Step 0291\tAverage Loss: 0.50\tAccuracy: 0.891\t\n",
            "Step 0292\tAverage Loss: 0.45\tAccuracy: 0.891\t\n",
            "Step 0293\tAverage Loss: 0.38\tAccuracy: 0.888\t\n",
            "Step 0294\tAverage Loss: 0.32\tAccuracy: 0.892\t\n",
            "Step 0295\tAverage Loss: 0.33\tAccuracy: 0.888\t\n",
            "Step 0296\tAverage Loss: 0.34\tAccuracy: 0.892\t\n",
            "Step 0297\tAverage Loss: 0.51\tAccuracy: 0.889\t\n",
            "Step 0298\tAverage Loss: 0.55\tAccuracy: 0.891\t\n",
            "Step 0299\tAverage Loss: 0.67\tAccuracy: 0.888\t\n",
            "Step 0300\tAverage Loss: 0.44\tAccuracy: 0.887\t\n",
            "Step 0301\tAverage Loss: 0.64\tAccuracy: 0.890\t\n",
            "Step 0302\tAverage Loss: 0.34\tAccuracy: 0.892\t\n",
            "Step 0303\tAverage Loss: 0.33\tAccuracy: 0.892\t\n",
            "Step 0304\tAverage Loss: 0.39\tAccuracy: 0.895\t\n",
            "Step 0305\tAverage Loss: 0.40\tAccuracy: 0.893\t\n",
            "Step 0306\tAverage Loss: 0.63\tAccuracy: 0.893\t\n",
            "Step 0307\tAverage Loss: 0.31\tAccuracy: 0.894\t\n",
            "Step 0308\tAverage Loss: 0.57\tAccuracy: 0.885\t\n",
            "Step 0309\tAverage Loss: 0.33\tAccuracy: 0.881\t\n",
            "Step 0310\tAverage Loss: 0.40\tAccuracy: 0.893\t\n",
            "Step 0311\tAverage Loss: 0.70\tAccuracy: 0.894\t\n",
            "Step 0312\tAverage Loss: 0.47\tAccuracy: 0.891\t\n",
            "Step 0313\tAverage Loss: 0.72\tAccuracy: 0.896\t\n",
            "Step 0314\tAverage Loss: 0.41\tAccuracy: 0.898\t\n",
            "Step 0315\tAverage Loss: 0.30\tAccuracy: 0.889\t\n",
            "Step 0316\tAverage Loss: 0.48\tAccuracy: 0.895\t\n",
            "Step 0317\tAverage Loss: 0.71\tAccuracy: 0.891\t\n",
            "Step 0318\tAverage Loss: 0.43\tAccuracy: 0.891\t\n",
            "Step 0319\tAverage Loss: 0.33\tAccuracy: 0.892\t\n",
            "Step 0320\tAverage Loss: 0.38\tAccuracy: 0.891\t\n",
            "Step 0321\tAverage Loss: 0.52\tAccuracy: 0.891\t\n",
            "Step 0322\tAverage Loss: 0.56\tAccuracy: 0.892\t\n",
            "Step 0323\tAverage Loss: 0.52\tAccuracy: 0.864\t\n",
            "Step 0324\tAverage Loss: 0.60\tAccuracy: 0.888\t\n",
            "Step 0325\tAverage Loss: 0.34\tAccuracy: 0.889\t\n",
            "Step 0326\tAverage Loss: 0.39\tAccuracy: 0.894\t\n",
            "Step 0327\tAverage Loss: 0.50\tAccuracy: 0.893\t\n",
            "Step 0328\tAverage Loss: 0.34\tAccuracy: 0.893\t\n",
            "Step 0329\tAverage Loss: 0.35\tAccuracy: 0.896\t\n",
            "Step 0330\tAverage Loss: 0.33\tAccuracy: 0.894\t\n",
            "Step 0331\tAverage Loss: 0.26\tAccuracy: 0.890\t\n",
            "Step 0332\tAverage Loss: 0.43\tAccuracy: 0.894\t\n",
            "Step 0333\tAverage Loss: 0.48\tAccuracy: 0.894\t\n",
            "Step 0334\tAverage Loss: 0.39\tAccuracy: 0.893\t\n",
            "Step 0335\tAverage Loss: 0.40\tAccuracy: 0.894\t\n",
            "Step 0336\tAverage Loss: 0.26\tAccuracy: 0.897\t\n",
            "Step 0337\tAverage Loss: 0.30\tAccuracy: 0.893\t\n",
            "Step 0338\tAverage Loss: 0.14\tAccuracy: 0.895\t\n",
            "Step 0339\tAverage Loss: 0.19\tAccuracy: 0.897\t\n",
            "Step 0340\tAverage Loss: 0.32\tAccuracy: 0.896\t\n",
            "Step 0341\tAverage Loss: 0.22\tAccuracy: 0.895\t\n",
            "Step 0342\tAverage Loss: 0.23\tAccuracy: 0.897\t\n",
            "Step 0343\tAverage Loss: 0.25\tAccuracy: 0.896\t\n",
            "Step 0344\tAverage Loss: 0.50\tAccuracy: 0.893\t\n",
            "Step 0345\tAverage Loss: 0.54\tAccuracy: 0.879\t\n",
            "Step 0346\tAverage Loss: 0.53\tAccuracy: 0.895\t\n",
            "Step 0347\tAverage Loss: 0.38\tAccuracy: 0.893\t\n",
            "Step 0348\tAverage Loss: 0.64\tAccuracy: 0.894\t\n",
            "Step 0349\tAverage Loss: 0.38\tAccuracy: 0.899\t\n",
            "Step 0350\tAverage Loss: 0.29\tAccuracy: 0.896\t\n",
            "Step 0351\tAverage Loss: 0.34\tAccuracy: 0.896\t\n",
            "Step 0352\tAverage Loss: 0.32\tAccuracy: 0.897\t\n",
            "Step 0353\tAverage Loss: 0.27\tAccuracy: 0.895\t\n",
            "Step 0354\tAverage Loss: 0.48\tAccuracy: 0.895\t\n",
            "Step 0355\tAverage Loss: 0.22\tAccuracy: 0.889\t\n",
            "Step 0356\tAverage Loss: 0.42\tAccuracy: 0.887\t\n",
            "Step 0357\tAverage Loss: 0.25\tAccuracy: 0.898\t\n",
            "Step 0358\tAverage Loss: 0.24\tAccuracy: 0.897\t\n",
            "Step 0359\tAverage Loss: 0.37\tAccuracy: 0.896\t\n",
            "Step 0360\tAverage Loss: 0.47\tAccuracy: 0.891\t\n",
            "Step 0361\tAverage Loss: 0.36\tAccuracy: 0.897\t\n",
            "Step 0362\tAverage Loss: 0.25\tAccuracy: 0.896\t\n",
            "Step 0363\tAverage Loss: 0.27\tAccuracy: 0.896\t\n",
            "Step 0364\tAverage Loss: 0.47\tAccuracy: 0.891\t\n",
            "Step 0365\tAverage Loss: 0.19\tAccuracy: 0.891\t\n",
            "Step 0366\tAverage Loss: 0.13\tAccuracy: 0.895\t\n",
            "Step 0367\tAverage Loss: 0.41\tAccuracy: 0.895\t\n",
            "Step 0368\tAverage Loss: 0.37\tAccuracy: 0.894\t\n",
            "Step 0369\tAverage Loss: 0.25\tAccuracy: 0.891\t\n",
            "Step 0370\tAverage Loss: 0.46\tAccuracy: 0.893\t\n",
            "Step 0371\tAverage Loss: 0.44\tAccuracy: 0.891\t\n",
            "Step 0372\tAverage Loss: 0.49\tAccuracy: 0.888\t\n",
            "Step 0373\tAverage Loss: 0.91\tAccuracy: 0.885\t\n",
            "Step 0374\tAverage Loss: 0.84\tAccuracy: 0.889\t\n",
            "Step 0375\tAverage Loss: 0.50\tAccuracy: 0.881\t\n",
            "Step 0376\tAverage Loss: 0.35\tAccuracy: 0.894\t\n",
            "Step 0377\tAverage Loss: 0.39\tAccuracy: 0.896\t\n",
            "Step 0378\tAverage Loss: 0.36\tAccuracy: 0.896\t\n",
            "Step 0379\tAverage Loss: 0.43\tAccuracy: 0.896\t\n",
            "Step 0380\tAverage Loss: 0.34\tAccuracy: 0.896\t\n",
            "Step 0381\tAverage Loss: 0.20\tAccuracy: 0.894\t\n",
            "Step 0382\tAverage Loss: 0.42\tAccuracy: 0.899\t\n",
            "Step 0383\tAverage Loss: 0.40\tAccuracy: 0.891\t\n",
            "Step 0384\tAverage Loss: 0.24\tAccuracy: 0.895\t\n",
            "Step 0385\tAverage Loss: 0.58\tAccuracy: 0.896\t\n",
            "Step 0386\tAverage Loss: 0.46\tAccuracy: 0.895\t\n",
            "Step 0387\tAverage Loss: 0.31\tAccuracy: 0.900\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wmFeH_bPotLk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}